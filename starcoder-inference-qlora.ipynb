{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-24T18:59:50.923354Z","iopub.execute_input":"2023-05-24T18:59:50.923704Z","iopub.status.idle":"2023-05-24T18:59:50.940966Z","shell.execute_reply.started":"2023-05-24T18:59:50.923651Z","shell.execute_reply":"2023-05-24T18:59:50.939966Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!huggingface-cli login --token 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","metadata":{"execution":{"iopub.status.busy":"2023-05-24T18:59:50.945023Z","iopub.execute_input":"2023-05-24T18:59:50.945309Z","iopub.status.idle":"2023-05-24T19:01:54.546321Z","shell.execute_reply.started":"2023-05-24T18:59:50.945285Z","shell.execute_reply":"2023-05-24T19:01:54.545004Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nmodel_id = \"bigcode/starcoderbase\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel_4bit = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2023-05-24T19:01:54.548252Z","iopub.execute_input":"2023-05-24T19:01:54.548997Z","iopub.status.idle":"2023-05-24T19:15:28.085333Z","shell.execute_reply.started":"2023-05-24T19:01:54.548955Z","shell.execute_reply":"2023-05-24T19:15:28.084224Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65320bfe417f484981b4438f30bca987"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/777k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d59338e63114b05b350cf1fafc0b859"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/442k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"766077e74fae44a99968308fe67cb0de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"660176d861ec4dc492f8226382e59429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/532 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d69102fbe9d483ab2827f75138c86ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4473ce973b304e7ca47ca06b93a7a681"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/36.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94ed8b3cd90d405281e4b01c7173ce90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdd55594c50048fcb1971afc92ceb255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00007.bin:   0%|          | 0.00/9.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54d41ced4e7b42b8b8dbca28cb3e69ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00007.bin:   0%|          | 0.00/9.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f269beeedbe4986a506367be0addf19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00003-of-00007.bin:   0%|          | 0.00/9.85G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fc935bb77094d35b524de8928efe3d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00004-of-00007.bin:   0%|          | 0.00/9.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8b446e073d6436d9dae432bd72c7f27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00005-of-00007.bin:   0%|          | 0.00/9.85G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42bd3c49d66347f59b41043887d34086"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00006-of-00007.bin:   0%|          | 0.00/9.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3891d12035543528ca893b8a42b0eda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00007-of-00007.bin:   0%|          | 0.00/4.08G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e7353415d54a739c0ad797ca277d4c"}},"metadata":{}},{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\nCUDA SETUP: Highest compute capability among GPUs detected: 6.0\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/cuda/lib')}\n  warn(msg)\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n  warn(msg)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f1b2f0925314dc7b7d0319086c2f60d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2d48727a46400bb754ac1b1046665a"}},"metadata":{}}]},{"cell_type":"code","source":"model_4bit.hf_device_map","metadata":{"execution":{"iopub.status.busy":"2023-05-24T19:15:28.092160Z","iopub.execute_input":"2023-05-24T19:15:28.093952Z","iopub.status.idle":"2023-05-24T19:15:28.101597Z","shell.execute_reply.started":"2023-05-24T19:15:28.093912Z","shell.execute_reply":"2023-05-24T19:15:28.100306Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'': 0}"},"metadata":{}}]},{"cell_type":"code","source":"import time\n\ndef generation(text, device, max_new_tokens=50):\n    st = time.time()\n    device = \"cuda:0\"\n    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n\n    outputs = model_4bit.generate(**inputs, max_new_tokens=max_new_tokens)\n    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n    et = time.time()\n    print(\"# get the execution time:\",et - st)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-24T19:32:46.260728Z","iopub.execute_input":"2023-05-24T19:32:46.261895Z","iopub.status.idle":"2023-05-24T19:32:46.269204Z","shell.execute_reply.started":"2023-05-24T19:32:46.261843Z","shell.execute_reply":"2023-05-24T19:32:46.268030Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"text = '''recur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#Summarize:'''\ngeneration(text, \"cuda:0\")","metadata":{"execution":{"iopub.status.busy":"2023-05-24T19:25:37.715928Z","iopub.execute_input":"2023-05-24T19:25:37.716334Z","iopub.status.idle":"2023-05-24T19:26:10.156067Z","shell.execute_reply.started":"2023-05-24T19:25:37.716302Z","shell.execute_reply":"2023-05-24T19:26:10.154855Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"recur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#Summarize:\n\tprint(recur_factorial(5))\n\tprint(recur_factorial(10))\n\tprint(recur_factorial(20))\n\tprint(recur_factorial(30))\n\tprint\n# get the execution time: 32.43457770347595\n","output_type":"stream"}]},{"cell_type":"code","source":"text = '''recur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#This'''\ngeneration(text, \"cuda:0\")","metadata":{"execution":{"iopub.status.busy":"2023-05-24T19:26:10.158282Z","iopub.execute_input":"2023-05-24T19:26:10.158887Z","iopub.status.idle":"2023-05-24T19:26:42.585985Z","shell.execute_reply.started":"2023-05-24T19:26:10.158846Z","shell.execute_reply":"2023-05-24T19:26:42.584862Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"recur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#This is the function that will be called to calculate the factorial of a number\n\tfactorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(\n# get the execution time: 32.42167592048645\n","output_type":"stream"}]},{"cell_type":"code","source":"text = '''recur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#This function'''\ngeneration(text, \"cuda:0\")","metadata":{"execution":{"iopub.status.busy":"2023-05-24T19:26:42.587473Z","iopub.execute_input":"2023-05-24T19:26:42.588734Z","iopub.status.idle":"2023-05-24T19:27:15.014108Z","shell.execute_reply.started":"2023-05-24T19:26:42.588693Z","shell.execute_reply":"2023-05-24T19:27:15.012988Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"recur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#This function will take a vector of numbers and return the factorial of each number in the vector\n\tfactorial <- function(x) {\n\treturn(sapply(x, recur_factorial))\n\t}\n\t#This function will\n# get the execution time: 32.420104026794434\n","output_type":"stream"}]},{"cell_type":"code","source":"text = '''\nrecur_factorial <- function(n) {\nif(n <= 1) {\nreturn(1)\n} else { \nreturn(n * recur_factorial(n-1))\n}\n}\n#Think step by step and write a final summary that states the functionality of the code above:\n'''\ngeneration(text, \"cuda:0\", max_new_tokens=100)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T19:32:49.761798Z","iopub.execute_input":"2023-05-24T19:32:49.762216Z","iopub.status.idle":"2023-05-24T19:33:54.528401Z","shell.execute_reply.started":"2023-05-24T19:32:49.762183Z","shell.execute_reply":"2023-05-24T19:33:54.527111Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"recur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#Think step by step and write a final summary that states the functionality of the code above:\n\t#1. The function takes in a number n and returns the factorial of n.\n\t#2. The function starts by checking if n is less than or equal to 1. If it is, the function returns 1.\n\t#3. If n is greater than 1, the function returns n times the factorial of n-1.\n\t#4. The function is recursive.\n\t#5. The function is named recur_factorial\n# get the execution time: 64.76068353652954\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HF Inference API","metadata":{}},{"cell_type":"code","source":"import requests\nimport time\n\nAPI_URL = \"https://api-inference.huggingface.co/models/bigcode/starcoder\"\nheaders = {\"Authorization\": \"Bearer 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\"}\n\ndef query(payload):\n    st = time.time()\n    response = requests.post(API_URL, headers=headers, json=payload)\n    et = time.time()\n    print(\"# get the execution time:\",et - st)\n    return response.json()","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:50:17.606369Z","iopub.execute_input":"2023-05-25T21:50:17.606724Z","iopub.status.idle":"2023-05-25T21:50:17.613193Z","shell.execute_reply.started":"2023-05-25T21:50:17.606697Z","shell.execute_reply":"2023-05-25T21:50:17.612057Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\n\n\noutput = query({\n\t\"inputs\": '''\nrecur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#Think step by step and write a final summary that states the functionality of the code above:''',\n    \"parameters\": {\"max_new_tokens\":250}\n})\n\nprint(output[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:50:46.154669Z","iopub.execute_input":"2023-05-25T21:50:46.155012Z","iopub.status.idle":"2023-05-25T21:50:46.467056Z","shell.execute_reply.started":"2023-05-25T21:50:46.154986Z","shell.execute_reply":"2023-05-25T21:50:46.466033Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"# get the execution time: 0.30684423446655273\n\n\t#1. What does the function do?\n\t#The function takes in a number and returns the factorial of that number.\n\t#2. What are the inputs?\n\t#The function takes in a number.\n\t#3. What are the outputs?\n\t#The function returns the factorial of the number.\n\t#4. What are the general steps?\n\t#The function takes in a number and checks if it is less than or equal to 1. If it is, the function returns 1. If it is not, the function returns the number multiplied by the factorial of the number minus 1.\n\t#5. What happens if the input is 0?\n\t#The function returns 1.\n\t#6. What happens if the input is negative?\n\t#The function returns an error.\n\t#7. What happens if the input is a decimal?\n\t#The function returns an error.\n\t#8. What happens if the input is a string?\n\t#The function returns an error.\n\t#9. What happens if the input is a vector?\n\t#The function returns an\n","output_type":"stream"}]},{"cell_type":"code","source":"output","metadata":{"execution":{"iopub.status.busy":"2023-05-25T19:07:08.237333Z","iopub.execute_input":"2023-05-25T19:07:08.237722Z","iopub.status.idle":"2023-05-25T19:07:08.244326Z","shell.execute_reply.started":"2023-05-25T19:07:08.237690Z","shell.execute_reply":"2023-05-25T19:07:08.243408Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'error': 'Service Unavailable'}"},"metadata":{}}]},{"cell_type":"code","source":"print(output)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:03:24.986611Z","iopub.execute_input":"2023-05-25T21:03:24.986960Z","iopub.status.idle":"2023-05-25T21:03:24.992407Z","shell.execute_reply.started":"2023-05-25T21:03:24.986933Z","shell.execute_reply":"2023-05-25T21:03:24.991363Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[{'generated_text': '\\n\\t#1. What does the function do?\\n\\t#The function takes in a number and returns the factorial of that number.\\n\\t#2. What are the inputs?\\n\\t#The function takes in a number.\\n\\t#3. What are the outputs?\\n\\t#The function returns the factorial of the number.\\n\\t#4. What are the general steps?\\n\\t#The function takes in a number and checks if it is less than or equal to 1. If it is, the function returns 1. If it is not, the function returns the number multiplied by the factorial of the number minus 1.\\n\\t#5. What happens if the input is 0?\\n\\t#The function returns 1.\\n\\t#6. What happens if the input is negative?\\n\\t#The function returns an error.\\n\\t#7. What happens if the input is a decimal?\\n\\t#The function returns an error.\\n\\t#8. What happens if the input is a string?\\n\\t#The function returns an error.\\n\\t#9. What happens if the input is a vector?\\n\\t#The function returns an'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random","metadata":{}},{"cell_type":"code","source":"from transformers import RobertaConfig, RobertaTokenizer, RobertaConfig, RobertaForMaskedLM, T5ForConditionalGeneration\nvictim_model = dict()\nvictim_model['model'] = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base-multi-sum')\nvictim_model['tokenizer'] = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\nvictim_model['model'].to('cuda:0')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:27:37.869905Z","iopub.execute_input":"2023-05-25T21:27:37.870276Z","iopub.status.idle":"2023-05-25T21:27:41.809082Z","shell.execute_reply.started":"2023-05-25T21:27:37.870246Z","shell.execute_reply":"2023-05-25T21:27:41.808197Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32100, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32100, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32100, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32100, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def _tokenize(seq, tokenizer, config):\n    if config['do_lower'] == 1:\n        seq = seq.replace('\\n', '').lower()\n    else:\n        seq = seq.replace('\\n', '')\n    seq = \" \".join(seq.split())\n    words = seq.split(' ')\n\n    sub_words = []\n    keys = []\n    index = 0\n    for word in words:\n        # Breaking a word into subwords\n        sub = tokenizer.tokenize(word)\n        sub_words += sub\n        # `keys`: Stores the starting and the ending index of each word. This is important\n        # because each word is broken into sub-words and we need to keep a track of \n        # each word's starting and ending index in the `sub_words` list.\n        keys.append([index, index + len(sub)])\n        index += len(sub)\n\n    return words, sub_words, keys, seq","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:22:26.560216Z","iopub.execute_input":"2023-05-25T21:22:26.560898Z","iopub.status.idle":"2023-05-25T21:22:26.569681Z","shell.execute_reply.started":"2023-05-25T21:22:26.560863Z","shell.execute_reply":"2023-05-25T21:22:26.568626Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"config = dict()\nconfig['do_lower'] = 0\nseq = '''\nrecur_factorial <- function(n) {\n\tif(n <= 1) {\n\treturn(1)\n\t} else { \n\treturn(n * recur_factorial(n-1))\n\t}\n\t}\n\t#Think step by step and write a final summary that states the functionality of the code above:'''\n# Preparing the code for input to the victim model\nwords, sub_words, keys, input_code = _tokenize(seq, victim_model['tokenizer'], config)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:22:27.765227Z","iopub.execute_input":"2023-05-25T21:22:27.765579Z","iopub.status.idle":"2023-05-25T21:22:27.779512Z","shell.execute_reply.started":"2023-05-25T21:22:27.765552Z","shell.execute_reply":"2023-05-25T21:22:27.778692Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"words, sub_words, keys, input_code","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:22:35.563879Z","iopub.execute_input":"2023-05-25T21:22:35.564260Z","iopub.status.idle":"2023-05-25T21:22:35.576562Z","shell.execute_reply.started":"2023-05-25T21:22:35.564229Z","shell.execute_reply":"2023-05-25T21:22:35.575515Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(['recur_factorial',\n  '<-',\n  'function(n)',\n  '{',\n  'if(n',\n  '<=',\n  '1)',\n  '{',\n  'return(1)',\n  '}',\n  'else',\n  '{',\n  'return(n',\n  '*',\n  'recur_factorial(n-1))',\n  '}',\n  '}',\n  '#Think',\n  'step',\n  'by',\n  'step',\n  'and',\n  'write',\n  'a',\n  'final',\n  'summary',\n  'that',\n  'states',\n  'the',\n  'functionality',\n  'of',\n  'the',\n  'code',\n  'above:'],\n ['re',\n  'cur',\n  '_',\n  'factor',\n  'ial',\n  '<',\n  '-',\n  'function',\n  '(',\n  'n',\n  ')',\n  '{',\n  'if',\n  '(',\n  'n',\n  '<',\n  '=',\n  '1',\n  ')',\n  '{',\n  'return',\n  '(',\n  '1',\n  ')',\n  '}',\n  'else',\n  '{',\n  'return',\n  '(',\n  'n',\n  '*',\n  're',\n  'cur',\n  '_',\n  'factor',\n  'ial',\n  '(',\n  'n',\n  '-',\n  '1',\n  '))',\n  '}',\n  '}',\n  '#',\n  'Th',\n  'ink',\n  'step',\n  'by',\n  'step',\n  'and',\n  'write',\n  'a',\n  'final',\n  'summary',\n  'that',\n  'states',\n  'the',\n  'function',\n  'ality',\n  'of',\n  'the',\n  'code',\n  'above',\n  ':'],\n [[0, 5],\n  [5, 7],\n  [7, 11],\n  [11, 12],\n  [12, 15],\n  [15, 17],\n  [17, 19],\n  [19, 20],\n  [20, 24],\n  [24, 25],\n  [25, 26],\n  [26, 27],\n  [27, 30],\n  [30, 31],\n  [31, 41],\n  [41, 42],\n  [42, 43],\n  [43, 46],\n  [46, 47],\n  [47, 48],\n  [48, 49],\n  [49, 50],\n  [50, 51],\n  [51, 52],\n  [52, 53],\n  [53, 54],\n  [54, 55],\n  [55, 56],\n  [56, 57],\n  [57, 59],\n  [59, 60],\n  [60, 61],\n  [61, 62],\n  [62, 64]],\n 'recur_factorial <- function(n) { if(n <= 1) { return(1) } else { return(n * recur_factorial(n-1)) } } #Think step by step and write a final summary that states the functionality of the code above:')"},"metadata":{}}]},{"cell_type":"code","source":"import torch\ncode_tokens = victim_model['tokenizer'].encode_plus(input_code, None, add_special_tokens=True, max_length=256)\ncode_ids  = torch.tensor(code_tokens[\"input_ids\"]).unsqueeze(0)\ncode_mask = code_ids.ne(victim_model['tokenizer'].pad_token_id).to('cuda:0')\nattention_mask = code_ids.ne(1)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:25:30.534192Z","iopub.execute_input":"2023-05-25T21:25:30.534847Z","iopub.status.idle":"2023-05-25T21:25:30.543090Z","shell.execute_reply.started":"2023-05-25T21:25:30.534816Z","shell.execute_reply":"2023-05-25T21:25:30.541937Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"config['task']='summarize'","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:26:18.023936Z","iopub.execute_input":"2023-05-25T21:26:18.024404Z","iopub.status.idle":"2023-05-25T21:26:18.029672Z","shell.execute_reply.started":"2023-05-25T21:26:18.024326Z","shell.execute_reply":"2023-05-25T21:26:18.028790Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"pred = victim_model['model'].generate(code_ids.to('cuda:0'), \n                                            attention_mask=code_mask,\n                                            output_scores=True,\n                                            return_dict_in_generate=True,\n                                            early_stopping=config['task']=='summarize',\n                                            max_length=128)    \npred_out = victim_model['tokenizer'].batch_decode(pred.sequences[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:27:53.995280Z","iopub.execute_input":"2023-05-25T21:27:53.995822Z","iopub.status.idle":"2023-05-25T21:27:56.980583Z","shell.execute_reply.started":"2023-05-25T21:27:53.995782Z","shell.execute_reply":"2023-05-25T21:27:56.979683Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:27:58.740537Z","iopub.execute_input":"2023-05-25T21:27:58.740891Z","iopub.status.idle":"2023-05-25T21:27:58.770363Z","shell.execute_reply.started":"2023-05-25T21:27:58.740865Z","shell.execute_reply":"2023-05-25T21:27:58.769558Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"GreedySearchEncoderDecoderOutput(sequences=tensor([[   0,    1,  426, 1397, 5578,  649,  445,    2]], device='cuda:0'), scores=(tensor([[13.3469, 27.3201,  5.3753,  ..., -1.1422, -1.2316,  5.4480]],\n       device='cuda:0'), tensor([[-0.6997,  3.8999,  1.5526,  ..., -1.0422, -0.7205, -0.0165]],\n       device='cuda:0'), tensor([[-0.9442,  3.0143,  3.4130,  ..., -1.1824, -1.3171, -0.1500]],\n       device='cuda:0'), tensor([[-0.9320,  0.4556,  6.0750,  ..., -3.2853, -1.9187, -1.7146]],\n       device='cuda:0'), tensor([[-1.0481, -0.0892,  6.8627,  ..., -2.7920, -1.5968, -1.8748]],\n       device='cuda:0'), tensor([[-1.1265, -0.0943,  9.2610,  ..., -4.3646, -1.2831, -1.9783]],\n       device='cuda:0'), tensor([[-0.6953, -0.1987, 14.1601,  ..., -4.7066, -3.7979, -2.6662]],\n       device='cuda:0')), encoder_attentions=None, encoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, decoder_hidden_states=None)"},"metadata":{}}]},{"cell_type":"code","source":"pred_out","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:28:01.836079Z","iopub.execute_input":"2023-05-25T21:28:01.836434Z","iopub.status.idle":"2023-05-25T21:28:01.842384Z","shell.execute_reply.started":"2023-05-25T21:28:01.836405Z","shell.execute_reply":"2023-05-25T21:28:01.841478Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['<pad>', '<s>', 'Re', 'cur', ' factor', 'ial', ' function', '</s>']"},"metadata":{}}]},{"cell_type":"code","source":"scores = pred.scores\nscores","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:28:03.256558Z","iopub.execute_input":"2023-05-25T21:28:03.256902Z","iopub.status.idle":"2023-05-25T21:28:03.272529Z","shell.execute_reply.started":"2023-05-25T21:28:03.256875Z","shell.execute_reply":"2023-05-25T21:28:03.271586Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(tensor([[13.3469, 27.3201,  5.3753,  ..., -1.1422, -1.2316,  5.4480]],\n        device='cuda:0'),\n tensor([[-0.6997,  3.8999,  1.5526,  ..., -1.0422, -0.7205, -0.0165]],\n        device='cuda:0'),\n tensor([[-0.9442,  3.0143,  3.4130,  ..., -1.1824, -1.3171, -0.1500]],\n        device='cuda:0'),\n tensor([[-0.9320,  0.4556,  6.0750,  ..., -3.2853, -1.9187, -1.7146]],\n        device='cuda:0'),\n tensor([[-1.0481, -0.0892,  6.8627,  ..., -2.7920, -1.5968, -1.8748]],\n        device='cuda:0'),\n tensor([[-1.1265, -0.0943,  9.2610,  ..., -4.3646, -1.2831, -1.9783]],\n        device='cuda:0'),\n tensor([[-0.6953, -0.1987, 14.1601,  ..., -4.7066, -3.7979, -2.6662]],\n        device='cuda:0'))"},"metadata":{}}]},{"cell_type":"code","source":"scores = torch.stack(list(scores)).squeeze()\nprint('*'*100)\nprint(scores)\npred_scores, pred_indices = torch.max(scores, dim=1)\nprint('*'*100)\nprint(pred_scores)\nprint('*'*100)\nprint(pred_indices)\npred_score = torch.sum(torch.tensor(pred_scores))\nprint('*'*100)\nprint(pred_score)","metadata":{"execution":{"iopub.status.busy":"2023-05-25T21:31:15.486123Z","iopub.execute_input":"2023-05-25T21:31:15.486501Z","iopub.status.idle":"2023-05-25T21:31:15.500767Z","shell.execute_reply.started":"2023-05-25T21:31:15.486470Z","shell.execute_reply":"2023-05-25T21:31:15.499831Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"****************************************************************************************************\ntensor([[ 1.3347e+01,  2.7320e+01,  5.3753e+00,  ..., -1.1422e+00,\n         -1.2316e+00,  5.4480e+00],\n        [-6.9966e-01,  3.8999e+00,  1.5526e+00,  ..., -1.0422e+00,\n         -7.2046e-01, -1.6539e-02],\n        [-9.4418e-01,  3.0143e+00,  3.4130e+00,  ..., -1.1824e+00,\n         -1.3171e+00, -1.4998e-01],\n        ...,\n        [-1.0481e+00, -8.9196e-02,  6.8627e+00,  ..., -2.7920e+00,\n         -1.5968e+00, -1.8748e+00],\n        [-1.1265e+00, -9.4340e-02,  9.2610e+00,  ..., -4.3646e+00,\n         -1.2831e+00, -1.9783e+00],\n        [-6.9534e-01, -1.9870e-01,  1.4160e+01,  ..., -4.7066e+00,\n         -3.7979e+00, -2.6662e+00]], device='cuda:0')\n****************************************************************************************************\ntensor([27.3201, 11.4927, 20.3274, 11.8502, 21.3518, 11.9610, 14.1601],\n       device='cuda:0')\n****************************************************************************************************\ntensor([   1,  426, 1397, 5578,  649,  445,    2], device='cuda:0')\n****************************************************************************************************\ntensor(118.4633, device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_28/3421539484.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  pred_score = torch.sum(torch.tensor(pred_scores))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}