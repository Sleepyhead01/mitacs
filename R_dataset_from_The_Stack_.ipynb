{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKC4tVj87p12"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_parquet('/content/train-00000-of-00001.parquet', engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "-DjRw0kU7xPx",
        "outputId": "f3be9ea2-9162-4ee9-d34f-c259b52a2da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         hexsha   size ext lang  \\\n",
              "0      f7018b9a471c73b4d04c85bdf2eb02bb2341ae55   1496   r    R   \n",
              "1      f70279428a98bb6a6fd14a6ebd960c24936349fd   5909   r    R   \n",
              "2      f702c4e6d9be3046e11976d530c9e5ac97c19dbc   9671   r    R   \n",
              "3      f704028c141c77117301ed7cc4f8739bf5a8e199   7036   r    R   \n",
              "4      f705b94bdb26e257adf614e8312ca524be62f320   3618   r    R   \n",
              "...                                         ...    ...  ..  ...   \n",
              "51872  73f678d2333bd88bb2cd5f84dc491508a2117728   3555   r    R   \n",
              "51873  73f76436b4a107ebbb67627813ed5eb7e659e450  11155   r    R   \n",
              "51874  73fa5953f805cebefa165c6a6f6f554dab5cfacd   1364   r    R   \n",
              "51875  73fb54a30c3d43593b0f2230df32470e1ee6c610   1185   r    R   \n",
              "51876  73fedcb5f867208e5d01843102ef4000202b938d   3757   r    R   \n",
              "\n",
              "                            max_stars_repo_path  \\\n",
              "0                       res/shift_accumulator.r   \n",
              "1                      covariate-size-effects.r   \n",
              "2                                R/PostitsApi.r   \n",
              "3                         R/Variance_Heatmaps.r   \n",
              "4                     mapdamage/r/stats/start.r   \n",
              "...                                         ...   \n",
              "51872             machine_learning/preprocess.r   \n",
              "51873                      data-raw/update_ab.r   \n",
              "51874                       R/plot_index_Neff.r   \n",
              "51875   examples/scaled_example/scripts/dge_0.r   \n",
              "51876  samples/client/petstore/r_test/R/Order.r   \n",
              "\n",
              "                  max_stars_repo_name  \\\n",
              "0                  JSpuri/EmuParadise   \n",
              "1                 payoto/covid19model   \n",
              "2       agaveplatform/agave-rlang-sdk   \n",
              "3                       ikuznet1/Amen   \n",
              "4                  ginolhac/mapDamage   \n",
              "...                               ...   \n",
              "51872  UrbanSkv/ela-transfer-learning   \n",
              "51873           epiforecasts/inc2prev   \n",
              "51874            liz-brooks/ASAPplots   \n",
              "51875                SD2E/omics_tools   \n",
              "51876    bruceadams/swagger-codegen-1   \n",
              "\n",
              "                     max_stars_repo_head_hexsha max_stars_repo_licenses  \\\n",
              "0      b8f6cf8823f8553f28dab5c6b44df20978ad6ba0                   [MIT]   \n",
              "1      f0b05e9cad206454bb43640489ffde07891cfbad                   [MIT]   \n",
              "2      b09f33d150103e7ef25945e742b8d0e8e9bb640d          [BSD-3-Clause]   \n",
              "3      204e4a65302c65a69b1f36e892aa094674201052            [Apache-2.0]   \n",
              "4      036806b434945594c2e642d03461c64e981507de                   [MIT]   \n",
              "...                                         ...                     ...   \n",
              "51872  0d71c4e90750347ce7ce1988bb7310124d41f4dc                   [MIT]   \n",
              "51873  a585e41bdbd38d1912648de114671478c02517e4          [BSD-3-Clause]   \n",
              "51874  f42263d80f28b9de5d1abd2f87676d26bb30d4ec                   [MIT]   \n",
              "51875  c1f4e3d84b5e5050605285bf2d16f40905e3e582                   [MIT]   \n",
              "51876  2e5289c4d74eafd48e3a324ccdd9e39323b5fb06            [Apache-2.0]   \n",
              "\n",
              "       max_stars_count max_stars_repo_stars_event_min_datetime  ...  \\\n",
              "0                  NaN                                    None  ...   \n",
              "1                  5.0                2020-04-07T06:58:25.000Z  ...   \n",
              "2                  1.0                2018-02-06T21:16:35.000Z  ...   \n",
              "3                  NaN                                    None  ...   \n",
              "4                 32.0                2015-03-11T21:29:32.000Z  ...   \n",
              "...                ...                                     ...  ...   \n",
              "51872              NaN                                    None  ...   \n",
              "51873             11.0                2022-01-18T19:50:11.000Z  ...   \n",
              "51874              2.0                2019-03-25T20:24:59.000Z  ...   \n",
              "51875              2.0                2021-06-17T17:39:27.000Z  ...   \n",
              "51876              NaN                                    None  ...   \n",
              "\n",
              "                  max_forks_repo_name  \\\n",
              "0                  JSpuri/EmuParadise   \n",
              "1                 payoto/covid19model   \n",
              "2          deardooley/agave-rlang-sdk   \n",
              "3                       ikuznet1/Amen   \n",
              "4                  ginolhac/mapDamage   \n",
              "...                               ...   \n",
              "51872  UrbanSkv/ela-transfer-learning   \n",
              "51873           epiforecasts/inc2prev   \n",
              "51874            liz-brooks/ASAPplots   \n",
              "51875                SD2E/omics_tools   \n",
              "51876    bruceadams/swagger-codegen-1   \n",
              "\n",
              "                     max_forks_repo_head_hexsha max_forks_repo_licenses  \\\n",
              "0      b8f6cf8823f8553f28dab5c6b44df20978ad6ba0                   [MIT]   \n",
              "1      f0b05e9cad206454bb43640489ffde07891cfbad                   [MIT]   \n",
              "2      b09f33d150103e7ef25945e742b8d0e8e9bb640d          [BSD-3-Clause]   \n",
              "3      204e4a65302c65a69b1f36e892aa094674201052            [Apache-2.0]   \n",
              "4      036806b434945594c2e642d03461c64e981507de                   [MIT]   \n",
              "...                                         ...                     ...   \n",
              "51872  0d71c4e90750347ce7ce1988bb7310124d41f4dc                   [MIT]   \n",
              "51873  a585e41bdbd38d1912648de114671478c02517e4          [BSD-3-Clause]   \n",
              "51874  f42263d80f28b9de5d1abd2f87676d26bb30d4ec                   [MIT]   \n",
              "51875  c1f4e3d84b5e5050605285bf2d16f40905e3e582                   [MIT]   \n",
              "51876  2e5289c4d74eafd48e3a324ccdd9e39323b5fb06            [Apache-2.0]   \n",
              "\n",
              "      max_forks_count max_forks_repo_forks_event_min_datetime  \\\n",
              "0                 NaN                                    None   \n",
              "1                 3.0                2020-04-12T16:31:47.000Z   \n",
              "2                 1.0                2018-02-08T18:52:28.000Z   \n",
              "3                 NaN                                    None   \n",
              "4                 6.0                2016-07-04T11:04:56.000Z   \n",
              "...               ...                                     ...   \n",
              "51872             NaN                                    None   \n",
              "51873             2.0                2022-01-20T09:29:47.000Z   \n",
              "51874             4.0                2019-08-23T19:14:55.000Z   \n",
              "51875             NaN                                    None   \n",
              "51876             NaN                                    None   \n",
              "\n",
              "       max_forks_repo_forks_event_max_datetime  \\\n",
              "0                                         None   \n",
              "1                     2020-04-20T21:34:57.000Z   \n",
              "2                     2018-02-08T18:52:28.000Z   \n",
              "3                                         None   \n",
              "4                     2021-12-20T21:16:47.000Z   \n",
              "...                                        ...   \n",
              "51872                                     None   \n",
              "51873                 2022-03-18T18:50:57.000Z   \n",
              "51874                 2021-03-18T19:36:49.000Z   \n",
              "51875                                     None   \n",
              "51876                                     None   \n",
              "\n",
              "                                                 content avg_line_length  \\\n",
              "0      | pc = 0xc002 | a = 0x00 | x = 0xaa | y = 0x00...       83.111111   \n",
              "1      library(ggplot2)\\n\\nselect_covariate_effects <...       44.765152   \n",
              "2      # Agave Platform Science API\\n#\\n# Power your ...       37.777344   \n",
              "3      #' Function for generated heatmap of the covar...       71.795918   \n",
              "4      #Runs likelihood optimization in the beginning...       33.813084   \n",
              "...                                                  ...             ...   \n",
              "51872  folder <- \"E:\\\\ML_Samples_new_2\\\\features\"\\r\\n...       31.184211   \n",
              "51873  library(\"here\")\\nlibrary(\"readxl\")\\nlibrary(\"r...       39.140351   \n",
              "51874  #' Plot effective sample size (Neff) by index\\...       38.971429   \n",
              "51875  suppressMessages(library(edgeR))\\noptions(scip...       32.027027   \n",
              "51876  # Swagger Petstore\\n# \\n# This is a sample ser...       29.124031   \n",
              "\n",
              "      max_line_length alphanum_fraction  \n",
              "0                  87          0.534091  \n",
              "1                 128          0.669318  \n",
              "2                 476          0.605418  \n",
              "3                 360          0.739198  \n",
              "4                 112          0.566611  \n",
              "...               ...               ...  \n",
              "51872              84          0.747679  \n",
              "51873             289          0.570417  \n",
              "51874             113          0.639296  \n",
              "51875             180          0.650633  \n",
              "51876             272          0.537131  \n",
              "\n",
              "[51877 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d062171-a50b-4560-8c3a-be18f6fc48f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hexsha</th>\n",
              "      <th>size</th>\n",
              "      <th>ext</th>\n",
              "      <th>lang</th>\n",
              "      <th>max_stars_repo_path</th>\n",
              "      <th>max_stars_repo_name</th>\n",
              "      <th>max_stars_repo_head_hexsha</th>\n",
              "      <th>max_stars_repo_licenses</th>\n",
              "      <th>max_stars_count</th>\n",
              "      <th>max_stars_repo_stars_event_min_datetime</th>\n",
              "      <th>...</th>\n",
              "      <th>max_forks_repo_name</th>\n",
              "      <th>max_forks_repo_head_hexsha</th>\n",
              "      <th>max_forks_repo_licenses</th>\n",
              "      <th>max_forks_count</th>\n",
              "      <th>max_forks_repo_forks_event_min_datetime</th>\n",
              "      <th>max_forks_repo_forks_event_max_datetime</th>\n",
              "      <th>content</th>\n",
              "      <th>avg_line_length</th>\n",
              "      <th>max_line_length</th>\n",
              "      <th>alphanum_fraction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f7018b9a471c73b4d04c85bdf2eb02bb2341ae55</td>\n",
              "      <td>1496</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>res/shift_accumulator.r</td>\n",
              "      <td>JSpuri/EmuParadise</td>\n",
              "      <td>b8f6cf8823f8553f28dab5c6b44df20978ad6ba0</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>JSpuri/EmuParadise</td>\n",
              "      <td>b8f6cf8823f8553f28dab5c6b44df20978ad6ba0</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>| pc = 0xc002 | a = 0x00 | x = 0xaa | y = 0x00...</td>\n",
              "      <td>83.111111</td>\n",
              "      <td>87</td>\n",
              "      <td>0.534091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f70279428a98bb6a6fd14a6ebd960c24936349fd</td>\n",
              "      <td>5909</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>covariate-size-effects.r</td>\n",
              "      <td>payoto/covid19model</td>\n",
              "      <td>f0b05e9cad206454bb43640489ffde07891cfbad</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2020-04-07T06:58:25.000Z</td>\n",
              "      <td>...</td>\n",
              "      <td>payoto/covid19model</td>\n",
              "      <td>f0b05e9cad206454bb43640489ffde07891cfbad</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2020-04-12T16:31:47.000Z</td>\n",
              "      <td>2020-04-20T21:34:57.000Z</td>\n",
              "      <td>library(ggplot2)\\n\\nselect_covariate_effects &lt;...</td>\n",
              "      <td>44.765152</td>\n",
              "      <td>128</td>\n",
              "      <td>0.669318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f702c4e6d9be3046e11976d530c9e5ac97c19dbc</td>\n",
              "      <td>9671</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>R/PostitsApi.r</td>\n",
              "      <td>agaveplatform/agave-rlang-sdk</td>\n",
              "      <td>b09f33d150103e7ef25945e742b8d0e8e9bb640d</td>\n",
              "      <td>[BSD-3-Clause]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-02-06T21:16:35.000Z</td>\n",
              "      <td>...</td>\n",
              "      <td>deardooley/agave-rlang-sdk</td>\n",
              "      <td>b09f33d150103e7ef25945e742b8d0e8e9bb640d</td>\n",
              "      <td>[BSD-3-Clause]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-02-08T18:52:28.000Z</td>\n",
              "      <td>2018-02-08T18:52:28.000Z</td>\n",
              "      <td># Agave Platform Science API\\n#\\n# Power your ...</td>\n",
              "      <td>37.777344</td>\n",
              "      <td>476</td>\n",
              "      <td>0.605418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f704028c141c77117301ed7cc4f8739bf5a8e199</td>\n",
              "      <td>7036</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>R/Variance_Heatmaps.r</td>\n",
              "      <td>ikuznet1/Amen</td>\n",
              "      <td>204e4a65302c65a69b1f36e892aa094674201052</td>\n",
              "      <td>[Apache-2.0]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>ikuznet1/Amen</td>\n",
              "      <td>204e4a65302c65a69b1f36e892aa094674201052</td>\n",
              "      <td>[Apache-2.0]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>#' Function for generated heatmap of the covar...</td>\n",
              "      <td>71.795918</td>\n",
              "      <td>360</td>\n",
              "      <td>0.739198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>f705b94bdb26e257adf614e8312ca524be62f320</td>\n",
              "      <td>3618</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>mapdamage/r/stats/start.r</td>\n",
              "      <td>ginolhac/mapDamage</td>\n",
              "      <td>036806b434945594c2e642d03461c64e981507de</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2015-03-11T21:29:32.000Z</td>\n",
              "      <td>...</td>\n",
              "      <td>ginolhac/mapDamage</td>\n",
              "      <td>036806b434945594c2e642d03461c64e981507de</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2016-07-04T11:04:56.000Z</td>\n",
              "      <td>2021-12-20T21:16:47.000Z</td>\n",
              "      <td>#Runs likelihood optimization in the beginning...</td>\n",
              "      <td>33.813084</td>\n",
              "      <td>112</td>\n",
              "      <td>0.566611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51872</th>\n",
              "      <td>73f678d2333bd88bb2cd5f84dc491508a2117728</td>\n",
              "      <td>3555</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>machine_learning/preprocess.r</td>\n",
              "      <td>UrbanSkv/ela-transfer-learning</td>\n",
              "      <td>0d71c4e90750347ce7ce1988bb7310124d41f4dc</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>UrbanSkv/ela-transfer-learning</td>\n",
              "      <td>0d71c4e90750347ce7ce1988bb7310124d41f4dc</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>folder &lt;- \"E:\\\\ML_Samples_new_2\\\\features\"\\r\\n...</td>\n",
              "      <td>31.184211</td>\n",
              "      <td>84</td>\n",
              "      <td>0.747679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51873</th>\n",
              "      <td>73f76436b4a107ebbb67627813ed5eb7e659e450</td>\n",
              "      <td>11155</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>data-raw/update_ab.r</td>\n",
              "      <td>epiforecasts/inc2prev</td>\n",
              "      <td>a585e41bdbd38d1912648de114671478c02517e4</td>\n",
              "      <td>[BSD-3-Clause]</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2022-01-18T19:50:11.000Z</td>\n",
              "      <td>...</td>\n",
              "      <td>epiforecasts/inc2prev</td>\n",
              "      <td>a585e41bdbd38d1912648de114671478c02517e4</td>\n",
              "      <td>[BSD-3-Clause]</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2022-01-20T09:29:47.000Z</td>\n",
              "      <td>2022-03-18T18:50:57.000Z</td>\n",
              "      <td>library(\"here\")\\nlibrary(\"readxl\")\\nlibrary(\"r...</td>\n",
              "      <td>39.140351</td>\n",
              "      <td>289</td>\n",
              "      <td>0.570417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51874</th>\n",
              "      <td>73fa5953f805cebefa165c6a6f6f554dab5cfacd</td>\n",
              "      <td>1364</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>R/plot_index_Neff.r</td>\n",
              "      <td>liz-brooks/ASAPplots</td>\n",
              "      <td>f42263d80f28b9de5d1abd2f87676d26bb30d4ec</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2019-03-25T20:24:59.000Z</td>\n",
              "      <td>...</td>\n",
              "      <td>liz-brooks/ASAPplots</td>\n",
              "      <td>f42263d80f28b9de5d1abd2f87676d26bb30d4ec</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2019-08-23T19:14:55.000Z</td>\n",
              "      <td>2021-03-18T19:36:49.000Z</td>\n",
              "      <td>#' Plot effective sample size (Neff) by index\\...</td>\n",
              "      <td>38.971429</td>\n",
              "      <td>113</td>\n",
              "      <td>0.639296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51875</th>\n",
              "      <td>73fb54a30c3d43593b0f2230df32470e1ee6c610</td>\n",
              "      <td>1185</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>examples/scaled_example/scripts/dge_0.r</td>\n",
              "      <td>SD2E/omics_tools</td>\n",
              "      <td>c1f4e3d84b5e5050605285bf2d16f40905e3e582</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2021-06-17T17:39:27.000Z</td>\n",
              "      <td>...</td>\n",
              "      <td>SD2E/omics_tools</td>\n",
              "      <td>c1f4e3d84b5e5050605285bf2d16f40905e3e582</td>\n",
              "      <td>[MIT]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>suppressMessages(library(edgeR))\\noptions(scip...</td>\n",
              "      <td>32.027027</td>\n",
              "      <td>180</td>\n",
              "      <td>0.650633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51876</th>\n",
              "      <td>73fedcb5f867208e5d01843102ef4000202b938d</td>\n",
              "      <td>3757</td>\n",
              "      <td>r</td>\n",
              "      <td>R</td>\n",
              "      <td>samples/client/petstore/r_test/R/Order.r</td>\n",
              "      <td>bruceadams/swagger-codegen-1</td>\n",
              "      <td>2e5289c4d74eafd48e3a324ccdd9e39323b5fb06</td>\n",
              "      <td>[Apache-2.0]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>...</td>\n",
              "      <td>bruceadams/swagger-codegen-1</td>\n",
              "      <td>2e5289c4d74eafd48e3a324ccdd9e39323b5fb06</td>\n",
              "      <td>[Apache-2.0]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td># Swagger Petstore\\n# \\n# This is a sample ser...</td>\n",
              "      <td>29.124031</td>\n",
              "      <td>272</td>\n",
              "      <td>0.537131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51877 rows × 29 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d062171-a50b-4560-8c3a-be18f6fc48f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d062171-a50b-4560-8c3a-be18f6fc48f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d062171-a50b-4560-8c3a-be18f6fc48f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vT3PYzJ98gF",
        "outputId": "0084c55f-b6b3-4211-bb0b-11b06bebc5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['hexsha', 'size', 'ext', 'lang', 'max_stars_repo_path',\n",
              "       'max_stars_repo_name', 'max_stars_repo_head_hexsha',\n",
              "       'max_stars_repo_licenses', 'max_stars_count',\n",
              "       'max_stars_repo_stars_event_min_datetime',\n",
              "       'max_stars_repo_stars_event_max_datetime', 'max_issues_repo_path',\n",
              "       'max_issues_repo_name', 'max_issues_repo_head_hexsha',\n",
              "       'max_issues_repo_licenses', 'max_issues_count',\n",
              "       'max_issues_repo_issues_event_min_datetime',\n",
              "       'max_issues_repo_issues_event_max_datetime', 'max_forks_repo_path',\n",
              "       'max_forks_repo_name', 'max_forks_repo_head_hexsha',\n",
              "       'max_forks_repo_licenses', 'max_forks_count',\n",
              "       'max_forks_repo_forks_event_min_datetime',\n",
              "       'max_forks_repo_forks_event_max_datetime', 'content', 'avg_line_length',\n",
              "       'max_line_length', 'alphanum_fraction'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rd_df = df.sample(5)\n",
        "for idx, row in rd_df.iterrows():\n",
        "  print(\"*\"*100)\n",
        "  print(row['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFKxPl-I-E_U",
        "outputId": "15b454dd-c619-419a-d183-2aa351e75243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "#Seed number for cross validation\n",
            "SEED=2014\n",
            "\n",
            "\n",
            "#Loading Required Libraries\n",
            "library(RWeka)#for PrincipalComponentAnalysis filter\n",
            "library(wavelets)#for discret wavelet transforms\n",
            "library(nnet)#training simple layer neural network\n",
            "library(matrixStats)#calculate std of columns\n",
            "library(pls)#multivariate regression\n",
            "library(monmlp)#training multilayer perceptron\n",
            "library(e1071)#training SVM\n",
            "library(prospectr)#preprocessing \n",
            "library(kernlab)# training gaussian process\n",
            "library(sqldf)#used for sampling dataset and cross validation split\n",
            "\n",
            "RMSE=function(real,pred)\n",
            "{\n",
            "\tnr=nrow(real)\n",
            "\tsm1=sqrt((1/nr)*(sum((real[,1]-pred[,1])^2)))\n",
            "\treturn (sm1)\n",
            "}\n",
            "\n",
            "#Discrete Wavelet Transforms using Haar Algorithm\n",
            "#DF1: input matrix for transform\n",
            "#nTimes: number of iterations \n",
            "HaarTransform=function(DF1,nTimes=1)\n",
            "{\n",
            "\tw =function(k)\n",
            "\t{\n",
            "\t\ts1=dwt(k, filter=\"haar\")\n",
            "\t\treturn (s1@V[[1]])\n",
            "\t}\n",
            "\tSmt=DF1\n",
            "\tfor (i in 1:nTimes)\n",
            "\t{\n",
            "\t\tSmt=t(apply(Smt,1,w))\n",
            "\t}\n",
            "\treturn (data.frame(Smt))\n",
            "}\n",
            "\n",
            "#Getting Derivatives \n",
            "#DF1: input matrix for transform\n",
            "#D: Order \n",
            "Derivative=function(DF1,D=1)\n",
            "{\n",
            "\tdf1=t(diff(t(DF1), differences = D))\t\n",
            "\treturn(df1)\n",
            "}\n",
            "\n",
            "#train MLP on train and then predict test using weights gained by train\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into monmlp function\n",
            "#Result is predicted values for test \n",
            "GetMLPPreds=function(train,test,Labels,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5,N.ensemble=10,LTh = tansig, LTo = linear,LTh.prime = tansig.prime, LTo.prime = linear.prime,Seed=1)\n",
            "{\n",
            "\tgc()\n",
            "\tset.seed(Seed)\n",
            "\tm1=monmlp.fit(as.matrix(train),as.matrix(Labels),scale.y=T,n.trials = 1, hidden1=Hidden1, hidden2=Hidden2, n.ensemble=N.ensemble,Th = LTh, To = LTo,\n",
            "\t Th.prime = LTh.prime, To.prime = LTo.prime,iter.max=Iters,monotone=NULL, bag=F, init.weights = c(-(IWeights),IWeights),max.exceptions = 10,silent = T)\n",
            "\tpr1=monmlp.predict(as.matrix(test),weights=m1)\n",
            "\trm(m1)\n",
            "\tgc()\n",
            "\treturn (data.frame(pr1))\t\n",
            "}\n",
            "\n",
            "#train simple layer neural network on train and then predict test using model gained by train\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into nnet function\n",
            "#Result is predicted values for test \n",
            "GetNNETPreds=function(train,test,Labels,Size=10,Rang=0.5,Decay=0.1,Iters=100,MaxWts=1500)\n",
            "{\n",
            "\tset.seed(1)\n",
            "\tg1=nnet((Labels)~.,data=train,size=Size,linout=T,skip =T, rang = Rang, decay = Decay,MaxNWts = MaxWts, maxit = Iters,trace=F)\n",
            "\tpr1=predict(g1,test)\n",
            "\trm(g1)\n",
            "\tgc()\n",
            "\treturn (data.frame(pr1))\t\n",
            "}\n",
            "\n",
            "#train SVM on train and then predict test using model gained by train\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into SVM function in e1071 library\n",
            "#Result is predicted values for test \n",
            "GetSVMPreds=function(train,test,Labels,Cost=10000)\n",
            "{\n",
            "\tset.seed(1)\n",
            "\ts1=svm(data.frame(train),Labels,scale = F,cost = Cost)\n",
            "\tpr1=(predict(s1,data.frame(test)))\n",
            "\treturn (data.frame(pr1))\t\t\n",
            "}\n",
            "\n",
            "#train GaussianProcess on train and then predict test using model gained by train\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into gausspr function in kernlab library\n",
            "#Result is predicted values for test \n",
            "GetGaussPreds=function(train,test,Labels,Kernel='rbfdot',Kpar='automatic',Tol=0.05,Var=0.01)\n",
            "{\n",
            "\tset.seed(1)\n",
            "\tv1=gausspr(data.frame(train), (Labels),type= NULL, kernel=Kernel,\n",
            "\t          kpar=Kpar, var=Var, variance.model = T, tol=Tol, cross=0, fit=F)\n",
            "\tpr1=(predict(v1,data.frame(test)))\n",
            "\trm(v1)\n",
            "\tgc()\n",
            "\treturn (data.frame(pr1))\t\t\t\n",
            "}\n",
            "\n",
            "#train MVR on train and then predict test using model gained by train\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into mvr function in pls library\n",
            "#Result is predicted values for test \n",
            "GetMVRPreds=function(train,test,Labels,Ncomp=120,Scale=True)\n",
            "{\n",
            "\tset.seed(1)\n",
            "\tv1=mvr(Labels~.,data=data.frame(train),ncomp=Ncomp, method = pls.options()$pcralg,scale = T)\n",
            "\tpr1=data.frame(predict(v1,data.frame(test)))\n",
            "\tpr1=data.frame(rowMeans(pr1))\n",
            "\trm(v1)\n",
            "\tgc()\n",
            "\treturn (data.frame(pr1))\t\t\t\n",
            "}\n",
            "\n",
            "\n",
            "#Seprate data sets based on \"Depth\" variable and then train two seperate mlp models and then combine results\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into monmlp function\n",
            "#Result is predicted values for test \n",
            "GetMLPDepthPreds=function(train,test,Labels,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5,N.ensemble=10,LTh = tansig, LTo = linear,LTh.prime = tansig.prime, LTo.prime = linear.prime,Seed=1)\n",
            "{\n",
            "\ttrainD1=train[train[,'Depth']==1,]\n",
            "\ttrainD2=train[train[,'Depth']==2,]\n",
            "\ttestD1=test[test[,'Depth']==1,]\n",
            "\ttestD2=test[test[,'Depth']==2,]\n",
            "\tprD1=GetMLPPreds(trainD1,testD1,MyTarget[train[,'Depth']==1],Iters=Iters,Hidden1=Hidden1,Hidden2=Hidden2,IWeights=IWeights,N.ensemble=N.ensemble,LTh = LTh, LTo = LTo,LTh.prime = LTh.prime, LTo.prime = LTo.prime,Seed=Seed)\n",
            "\tcolnames(prD1)[1]='pr'\n",
            "\tprD2=GetMLPPreds(trainD2,testD2,MyTarget[train[,'Depth']==2],Iters=Iters,Hidden1=Hidden1,Hidden2=Hidden2,IWeights=IWeights,N.ensemble=N.ensemble,LTh = LTh, LTo = LTo,LTh.prime = LTh.prime, LTo.prime = LTo.prime,Seed=Seed)\n",
            "\tcolnames(prD2)[1]='pr'\n",
            "\tprD=rbind(prD1,prD2)\n",
            "\tprD[test[,'Depth']==1,1]=prD1\n",
            "\tprD[test[,'Depth']==2,1]=prD2\n",
            "\treturn (data.frame(prD))\n",
            "}\n",
            "\n",
            "#Seprate data sets based on \"Depth\" variable and then train two seperate svm models and then combine results\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into svm function\n",
            "#Result is predicted values for test \n",
            "GetSVMDepthPreds=function(train,test,Labels,Cost=10000)\n",
            "{\n",
            "\ttrain=train\n",
            "\ttest=test\n",
            "\ttrainD1=train[train[,'Depth']==1,-ncol(train)]\n",
            "\ttrainD2=train[train[,'Depth']==2,-ncol(train)]\n",
            "\ttestD1=test[test[,'Depth']==1,-ncol(train)]\n",
            "\ttestD2=test[test[,'Depth']==2,-ncol(train)]\n",
            "\tprD1=GetSVMPreds(trainD1,testD1,MyTarget[train[,'Depth']==1],Cost=Cost)\n",
            "\tcolnames(prD1)[1]='pr'\n",
            "\tprD2=GetSVMPreds(trainD2,testD2,MyTarget[train[,'Depth']==2],Cost=Cost)\n",
            "\tcolnames(prD2)[1]='pr'\n",
            "\tprD=rbind(prD1,prD2)\n",
            "\tprD[test[,'Depth']==1,1]=prD1\n",
            "\tprD[test[,'Depth']==2,1]=prD2\n",
            "\treturn (data.frame(prD))\n",
            "}\n",
            "\n",
            "#Seprate data sets based on \"Depth\" variable and then train two seperate gaussian process models and then combine results\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into gausspr function\n",
            "#Result is predicted values for test \n",
            "GetGaussDepthPreds=function(train,test,Labels,Kernel='rbfdot',Kpar='automatic',Tol=0.05,Var=0.01)\n",
            "{\n",
            "\ttrain=train\n",
            "\ttest=test\n",
            "\ttrainD1=train[train[,'Depth']==1,-ncol(train)]\n",
            "\ttrainD2=train[train[,'Depth']==2,-ncol(train)]\n",
            "\ttestD1=test[test[,'Depth']==1,-ncol(train)]\n",
            "\ttestD2=test[test[,'Depth']==2,-ncol(train)]\n",
            "\tprD1=GetGaussPreds(trainD1,testD1,MyTarget[train[,'Depth']==1],Kernel=Kernel,Kpar=Kpar,Tol=Tol,Var=Var)\n",
            "\tcolnames(prD1)[1]='pr'\n",
            "\tprD2=GetGaussPreds(trainD2,testD2,MyTarget[train[,'Depth']==2],Kernel=Kernel,Kpar=Kpar,Tol=Tol,Var=Var)\n",
            "\tcolnames(prD2)[1]='pr'\n",
            "\tprD=rbind(prD1,prD2)\n",
            "\tprD[test[,'Depth']==1,1]=prD1\n",
            "\tprD[test[,'Depth']==2,1]=prD2\n",
            "\treturn (data.frame(prD))\n",
            "}\n",
            "\n",
            "#Seprate data sets based on \"Depth\" variable and then train two seperate mvr process models and then combine results\n",
            "#train: train data frame for training\n",
            "#test: test data frame to predict\n",
            "#Other parameters are passed into mvr function\n",
            "#Result is predicted values for test \n",
            "GetMVRDepthPreds=function(train,test,Labels,Ncomp=120,Scale=True)\n",
            "{\n",
            "\ttrain=train\n",
            "\ttest=test\n",
            "\ttrainD1=train[train[,'Depth']==1,-ncol(train)]\n",
            "\ttrainD2=train[train[,'Depth']==2,-ncol(train)]\n",
            "\ttestD1=test[test[,'Depth']==1,-ncol(train)]\n",
            "\ttestD2=test[test[,'Depth']==2,-ncol(train)]\n",
            "\tprD1=GetMVRPreds(trainD1,testD1,MyTarget[train[,'Depth']==1],Ncomp=Ncomp,Scale=Scale)\n",
            "\tcolnames(prD1)[1]='pr'\n",
            "\tprD2=GetMVRPreds(trainD2,testD2,MyTarget[train[,'Depth']==2],Ncomp=Ncomp,Scale=Scale)\n",
            "\tcolnames(prD2)[1]='pr'\n",
            "\tprD=rbind(prD1,prD2)\n",
            "\tprD[test[,'Depth']==1,1]=prD1\n",
            "\tprD[test[,'Depth']==2,1]=prD2\n",
            "\treturn (data.frame(prD))\n",
            "}\n",
            "\n",
            "#Calcule PCA using Weka PrincipalComponents filter\n",
            "#df: input data frame \n",
            "#var: variance parameter for PCA\n",
            "WekPCA=function(df,var)\n",
            "{\n",
            "\tpc=make_Weka_filter('weka/filters/unsupervised/attribute/PrincipalComponents')\n",
            "\td1=pc(df[,1]~.,data=df[,-1],control=c('-R',var))\n",
            "\treturn (d1[,-ncol(d1)])\n",
            "}\n",
            "\n",
            "#Combine train and test and then get rank of features based on their standard deviation\n",
            "#trainDF:train data frame\n",
            "#testDF:train data frame\n",
            "#result is rank of features\n",
            "GetRanksBySD=function(trainDF,testDF)\n",
            "{\n",
            "\tTAT=rbind(trainDF,testDF)\n",
            "\trnk=rank(colSds(as.matrix(TAT)))\n",
            "\treturn (rnk)\n",
            "}\n",
            "\n",
            "#Reading Dataset\n",
            "TrainAndTestM=read.csv('training.csv')\n",
            "TrainAndTestM[,3595]=as.numeric(TrainAndTestM[,3595])\n",
            "#################\n",
            "#################\n",
            "#Sampling Dataset based on TMAP variable\n",
            "TMAP=sqldf('select distinct TMAP from TrainAndTestM order by TMAP')\n",
            "set.seed(SEED)\n",
            "TMAPS=data.frame(TMAP[sample(nrow(TMAP)),])\n",
            "TMAPS=cbind(1:nrow(TMAPS),TMAPS)\n",
            "colnames(TMAPS)[1]='Ord'\n",
            "colnames(TMAPS)[2]='TMAP'\n",
            "ttt=sqldf('select i.*,j.Ord from TrainAndTestM i left join TMAPS j on (i.TMAP=j.TMAP)')\n",
            "TrainAndTest=TrainAndTestM[order(ttt[,'Ord']),]\n",
            "#calcule partial PCs of combined data set\n",
            "#devide data set into 30 sub frames and then getting PCs \n",
            "#the combine sub-frames \n",
            "PC=list()\n",
            "for (i in 1:30)\n",
            "{\n",
            "\tj1=(i-1)*119+2\n",
            "\tj2=(i)*119+1\n",
            "\tif (i==30)\n",
            "\t{\n",
            "\t\tj2=3579\n",
            "\t}\t\n",
            "\ttemp1=TrainAndTest[,j1:j2]\n",
            "\tflush.console()\n",
            "\tPC[[i]]=WekPCA(cbind(TrainAndTest['Ca'],temp1),0.999)\t\n",
            "}\n",
            "PComponents=PC[[1]]\n",
            "for (i in 2:30)\n",
            "{\n",
            "\tPComponents=cbind(PComponents,PC[[i]])\n",
            "}\n",
            "\n",
            "#Multiple Scatter Correction on spectral features(two phases) \n",
            "TrainAndTestReduced=msc(as.matrix(TrainAndTest[,2:3579]))\n",
            "TrainAndTestReduced=msc(as.matrix(TrainAndTestReduced))\n",
            "\n",
            "#First Derivatives\n",
            "TrainAndTestReduced=Derivative(TrainAndTestReduced,1)\n",
            "\n",
            "#Original data set(without transformation)\n",
            "TrainAndTestOriginal=TrainAndTest[2:3600]\n",
            "\n",
            "#Reduced Dataset(PCA,DWT)\n",
            "TrainAndTestReduced=cbind(PComponents,data.frame(HaarTransform(TrainAndTestReduced,9)),TrainAndTest[,3580:3600])\n",
            "\n",
            "#Creating data frame for submission\n",
            "#submission=data.frame(PIDN=TestDataSet['PIDN'],Ca=1:nrow(TestDataSet),P=1:nrow(TestDataSet),pH=1:nrow(TestDataSet),SOC=1:nrow(TestDataSet),Sand=1:nrow(TestDataSet))\n",
            "#k=2#Counter of submission columns\n",
            "msm=0\n",
            "nf=5\n",
            "cat('Seed Number:',SEED,'\\n')\n",
            "for (TheTarget in c('Ca','P','pH','SOC','Sand'))\n",
            "#for (TheTarget in c('pH'))\n",
            "{\n",
            "\tcvsm=0\n",
            "\tcat (TheTarget,'.....................................................................\\n')\n",
            "\tfor (cv in 1:nf)\n",
            "\t{\n",
            "\t\tcat('CV',cv,':-------------------------------------\\n')\n",
            "\t\tnd=floor(nrow(TrainAndTestReduced)/nf)\n",
            "\t\ttestindexes=((cv-1)*nd+1):(cv*nd)\n",
            "\t\t#Retriving train and test data frames from original data set\n",
            "\t\ttrainOriginal=TrainAndTestOriginal[-(testindexes),]\n",
            "\t\ttestOriginal=TrainAndTestOriginal[(testindexes),]\n",
            "\t\ttstTRG=testOriginal[TheTarget]\n",
            "\t\t#Retriving train and test data frames from reduced data set\t\n",
            "\t\ttrainReduced=TrainAndTestReduced[-(testindexes),]\n",
            "\t\ttestReduced=TrainAndTestReduced[(testindexes),]\n",
            "\t\t\t\n",
            "\t\tThisTarget=trainOriginal[,TheTarget]\n",
            "\t\tMyTarget=trainOriginal[,TheTarget]\n",
            "\t\t\n",
            "\t\t#Saturation and log transform for \"P\" target\n",
            "\t\tif (TheTarget=='P')\n",
            "\t\t{\n",
            "\t\t\tMyTarget=ifelse(MyTarget>6,6,MyTarget)\n",
            "\t\t\tMyTarget=log(1+MyTarget)\n",
            "\t\t}\n",
            "\t\t\n",
            "\t\ttrainReduced=trainReduced[,!colnames(trainReduced)%in% c('Ca','P','pH','SOC','Sand')]\n",
            "\t\ttestReduced=testReduced[,!colnames(testReduced)%in% c('Ca','P','pH','SOC','Sand')]\n",
            "\t\ttrainOriginal=trainOriginal[,!colnames(trainOriginal)%in% c('Ca','P','pH','SOC','Sand')]\n",
            "\t\ttestOriginal=testOriginal[,!colnames(testOriginal)%in% c('Ca','P','pH','SOC','Sand')]\n",
            "\t\t\n",
            "\t\t#Training and Prediction phase for \"Ca\" target\n",
            "\t\tif (TheTarget=='Ca')\n",
            "\t\t{\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 3, w = 21, m = 0)#savitzkyGolay filter from prospectr library\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 3, w = 21, m = 0)\n",
            "\t\t\tMyTrain=cbind(MyTrain,trainOriginal[c(3583,3586,3587,3588,3589,3591,3594)])\n",
            "\t\t\tMyTest=cbind(MyTest,testOriginal[c(3583,3586,3587,3588,3589,3591,3594)])\t\t\n",
            "\t\t\tCa_SVM_Preds1=GetSVMPreds(MyTrain,MyTest,MyTarget,1000)\n",
            "\t\t\tcat('Ca_SVM_Preds1:',RMSE(data.frame(tstTRG),Ca_SVM_Preds1),'   ')\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tCa_SVM_Preds2=GetSVMPreds(trainOriginal,testOriginal,MyTarget,Cost=10000)\n",
            "\t\t\tcat('Ca_SVM_Preds2:',RMSE(data.frame(tstTRG),Ca_SVM_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tCa_SVM_Preds3=GetSVMPreds(trainOriginal,testOriginal,MyTarget,5000)\n",
            "\t\t\tcat('Ca_SVM_Preds3:',RMSE(data.frame(tstTRG),Ca_SVM_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal\n",
            "\t\t\tMyTest=testOriginal\n",
            "\t\t\tSSS=(rbind(MyTrain,MyTest))\n",
            "\t\t\t#get first 2000 features order by their standard deviation\n",
            "\t\t\tordr=colnames(SSS)[order(colSds(as.matrix(SSS)),decreasing=T)]\n",
            "\t\t\tMyTrain=MyTrain[,ordr[1:2000]]\t\t\n",
            "\t\t\tMyTest=MyTest[,ordr[1:2000]]\t\t\t\n",
            "\t\t\tMyTrain=HaarTransform(Derivative(MyTrain),3)\n",
            "\t\t\tMyTest=HaarTransform(Derivative(MyTest),3)\n",
            "\t\t\tCa_SVM_Preds4=GetSVMPreds(MyTrain,MyTest,MyTarget,10000)\n",
            "\t\t\tcat('Ca_SVM_Preds4:',RMSE(data.frame(tstTRG),Ca_SVM_Preds4),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\t#Get 2500 features with highest standard deviation\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(HaarTransform(MyTrain,4),trainOriginal[c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(MyTest,4),testOriginal[c(3579:3581)])\t\t\n",
            "\t\t\t#Get average of 10 different mlp model with different seed numbers\n",
            "\t\t\tCa_MLP_Preds1=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=4,Hidden2=4,IWeights=0.5,Seed=1,N.ensemble=2)\n",
            "\t\t\tCNT=10\n",
            "\t\t\tfor (sd in 2:CNT)\n",
            "\t\t\t{\n",
            "\t\t\t\tCa_MLP_Preds1=Ca_MLP_Preds1+GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=4,Hidden2=4,IWeights=0.5,Seed=sd,N.ensemble=2)\n",
            "\t\t\t\tflush.console()\n",
            "\t\t\t}\t\t\n",
            "\t\t\tCa_MLP_Preds1=Ca_MLP_Preds1/CNT\t\n",
            "\t\t\tcat('Ca_MLP_Preds1:',RMSE(data.frame(tstTRG),Ca_MLP_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 3, w = 11, m = 0)\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 3, w = 11, m = 0)\n",
            "\t\t\tMyTrain=cbind(HaarTransform(MyTrain,4),trainOriginal[c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(HaarTransform((MyTest),4),testOriginal[c(3579:3581)])\t\t\n",
            "\t\t\tCa_MLP_Preds2=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=4,Hidden2=4,IWeights=0.5,Seed=1,N.ensemble=10)\n",
            "\t\t\tcat('Ca_MLP_Preds2:',RMSE(data.frame(tstTRG),Ca_MLP_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal[,1:3578],5),trainOriginal[,c(3579,3581)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal[,1:3578],5),testOriginal[,c(3579,3581)])\n",
            "\t\t\tCa_MLP_Preds3=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('Ca_MLP_Preds3:',RMSE(data.frame(tstTRG),Ca_MLP_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(Derivative(trainOriginal[,1:3578]),7),trainOriginal[,c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(Derivative(testOriginal[,1:3578]),7),testOriginal[,c(3579:3581)])\n",
            "\t\t\tCa_MLP_Preds4=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=3,Hidden2=20,IWeights=0.6)\t\t\n",
            "\t\t\tcat('Ca_MLP_Preds4:',RMSE(data.frame(tstTRG),Ca_MLP_Preds4),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(trainOriginal,4)),trainOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(testOriginal,4)),testOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tCa_MLP_Preds5=GetMLPDepthPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\n",
            "\t\t\tcat('Ca_MLP_Preds5:',RMSE(data.frame(tstTRG),Ca_MLP_Preds5),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal,5),trainOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal,5),testOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tCa_MLP_Preds6=GetMLPDepthPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\n",
            "\t\t\tcat('Ca_MLP_Preds6:',RMSE(data.frame(tstTRG),Ca_MLP_Preds6),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal[,1:3578],4),trainOriginal[,c(3579:3582)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal[,1:3578],4),testOriginal[,c(3579:3582)])\n",
            "\t\t\tCa_MLP_Preds7=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('Ca_MLP_Preds7:',RMSE(data.frame(tstTRG),Ca_MLP_Preds7),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal[,1:3578],3),trainOriginal[,c(3579:3582)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal[,1:3578],3),testOriginal[,c(3579:3582)])\n",
            "\t\t\tCa_MLP_Preds8=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('Ca_MLP_Preds8:',RMSE(data.frame(tstTRG),Ca_MLP_Preds8),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tCa_Gauss_Preds1=GetGaussPreds(trainOriginal,testOriginal,MyTarget,Kernel='rbfdot',Tol=0.05,Var=0.01)\n",
            "\t\t\tcat('Ca_Gauss_Preds1:',RMSE(data.frame(tstTRG),Ca_Gauss_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tCa_Gauss_Preds2=GetGaussPreds(trainReduced,testReduced,MyTarget,Kernel='rbfdot',Tol=0.05,Var=0.01)\n",
            "\t\t\tcat('Ca_Gauss_Preds2:',RMSE(data.frame(tstTRG),Ca_Gauss_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tCa_Gauss_Preds3=GetGaussPreds(trainOriginal,testOriginal,MyTarget,Kernel='polydot',Tol=0.001,Var=0.1)\n",
            "\t\t\tcat('Ca_Gauss_Preds3:',RMSE(data.frame(tstTRG),Ca_Gauss_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal\n",
            "\t\t\tMyTest=testOriginal\n",
            "\t\t\tSSS=(rbind(MyTrain,MyTest))\n",
            "\t\t\tordr=colnames(SSS)[order(colSds(as.matrix(SSS)),decreasing=T)]\n",
            "\t\t\tMyTrain=MyTrain[,ordr[1:2000]]\t\t\n",
            "\t\t\tMyTest=MyTest[,ordr[1:2000]]\t\t\t\n",
            "\t\t\tCa_MVR_Preds1=GetMVRPreds(MyTrain,MyTest,MyTarget,120,True)\n",
            "\t\t\tcat('Ca_MVR_Preds1:',RMSE(data.frame(tstTRG),Ca_MVR_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\t\t\t\t\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tCa_MVR_Preds2=GetMVRPreds(trainOriginal,testOriginal,MyTarget,100,True)\n",
            "\t\t\tcat('Ca_MVR_Preds2:',RMSE(data.frame(tstTRG),Ca_MVR_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=HaarTransform(trainOriginal,5)\n",
            "\t\t\tMyTest=HaarTransform(testOriginal,5)\n",
            "\t\t\tCa_NNET_Preds1=GetNNETPreds(MyTrain,MyTest,MyTarget,Size=10,Rang=0.5,Decay=0.1,Iters=100)\t\t\n",
            "\t\t\tcat('Ca_NNET_Preds1:',RMSE(data.frame(tstTRG),Ca_NNET_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\t#Combining predictions\n",
            "\t\t\tThisPred=(100*Ca_SVM_Preds1+100*Ca_MLP_Preds1+100*Ca_MLP_Preds2+15*Ca_Gauss_Preds1+30*Ca_SVM_Preds2+100*Ca_SVM_Preds3+45*Ca_Gauss_Preds2+10*Ca_Gauss_Preds3+15*Ca_MVR_Preds1+10*Ca_SVM_Preds4+150*Ca_MLP_Preds3+50*Ca_MLP_Preds4+10*Ca_NNET_Preds1+5*Ca_MVR_Preds2+30*Ca_MLP_Preds5+30*Ca_MLP_Preds6+150*Ca_MLP_Preds7+50*Ca_MLP_Preds8)/1000\t\t\n",
            "\t\t\tcat('Ca_Ensemble:',RMSE(data.frame(tstTRG),ThisPred),' \\n  ')\t\n",
            "\t\t\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t}\n",
            "\t\t\n",
            "\t\t#Training and Prediction phase for \"P\" target\n",
            "\t\tif (TheTarget=='P')\n",
            "\t\t{\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=((trainOriginal[,1:3578]))\n",
            "\t\t\tMyTest=((testOriginal[,1:3578]))\n",
            "\t\t\tMyTrain=continuumRemoval(MyTrain, type='R',method='substraction')#continuumRemoval from prospectr library\n",
            "\t\t\tMyTest=continuumRemoval(MyTest, type='R',method='substraction')\n",
            "\t\t\tMyTrain=ifelse(is.na(MyTrain),1,MyTrain)\n",
            "\t\t\tMyTest=ifelse(is.na(MyTest),1,MyTest)\n",
            "\t\t\tMyTrain=cbind(MyTrain,trainOriginal[c(3579,3582)])\n",
            "\t\t\tMyTest=cbind(MyTest,testOriginal[c(3579,3582)])\t\t\n",
            "\t\t\tP_SVM_Preds1=GetSVMPreds(MyTrain,MyTest,MyTarget,5000)\n",
            "\t\t\tP_SVM_Preds1[,1]=exp(P_SVM_Preds1[,1])-1\n",
            "\t\t\tcat('P_SVM_Preds1:',RMSE(data.frame(tstTRG),P_SVM_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(trainOriginal[,1:3578],trainOriginal[,3579:3594])\n",
            "\t\t\tMyTest=cbind(testOriginal[,1:3578],testOriginal[,3579:3594])\n",
            "\t\t\tP_SVM_Preds2=GetSVMPreds(MyTrain,MyTest,MyTarget,5000)\n",
            "\t\t\tP_SVM_Preds2[,1]=exp(P_SVM_Preds2[,1])-1\n",
            "\t\t\tcat('P_SVM_Preds2:',RMSE(data.frame(tstTRG),P_SVM_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal[,1:3578],1),trainOriginal[c(3583,3594)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal[,1:3578],1),testOriginal[c(3583,3594)])\n",
            "\t\t\tP_SVM_Preds3=GetSVMDepthPreds(MyTrain,MyTest,MyTarget,Cost=1000)\n",
            "\t\t\tP_SVM_Preds3[,1]=exp(P_SVM_Preds3[,1])-1\n",
            "\t\t\tcat('P_SVM_Preds3:',RMSE(data.frame(tstTRG),P_SVM_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=((trainOriginal[,1:3578]))\n",
            "\t\t\tMyTest=((testOriginal[,1:3578]))\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 4, w = 11, m = 1)\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 4, w = 11, m = 1)\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<3000]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<3000]\t\t\t\n",
            "\t\t\tMyTrain=cbind(HaarTransform(MyTrain,4),trainOriginal[c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(MyTest,4),testOriginal[c(3579:3581,3594)])\t\t\n",
            "\t\t\tP_MLP_Preds1=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=5,Hidden2=0,IWeights=0.5)\t\t\n",
            "\t\t\tP_MLP_Preds1[,1]=exp(P_MLP_Preds1[,1])-1\n",
            "\t\t\tcat('P_MLP_Preds1:',RMSE(data.frame(tstTRG),P_MLP_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 4, w = 11, m = 1)\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 4, w = 11, m = 1)\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(HaarTransform(MyTrain,4),trainOriginal[c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(MyTest,4),testOriginal[c(3579:3581,3594)])\t\t\n",
            "\t\t\tP_MLP_Preds2=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=4,Hidden2=4,IWeights=0.6,Seed=1,N.ensemble=5)\n",
            "\t\t\tP_MLP_Preds2[,1]=exp(P_MLP_Preds2[,1])-1\n",
            "\t\t\tcat('P_MLP_Preds2:',RMSE(data.frame(tstTRG),P_MLP_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\t\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(trainOriginal,4)),trainOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(testOriginal,4)),testOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tP_MLP_Preds3=GetMLPDepthPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\n",
            "\t\t\tP_MLP_Preds3[,1]=exp(P_MLP_Preds3[,1])-1\n",
            "\t\t\tcat('P_MLP_Preds3:',RMSE(data.frame(tstTRG),P_MLP_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=HaarTransform(trainOriginal,5)\n",
            "\t\t\tMyTest=HaarTransform(testOriginal,5)\n",
            "\t\t\tP_MLP_Preds4=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=50,Hidden1=5,Hidden2=5,IWeights=0.6)\t\t\n",
            "\t\t\tP_MLP_Preds4[,1]=exp(P_MLP_Preds4[,1])-1\n",
            "\t\t\tcat('P_MLP_Preds4:',RMSE(data.frame(tstTRG),P_MLP_Preds4),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=cbind(HaarTransform(Derivative(MyTrain),2),trainOriginal[,c(3579,3593)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(Derivative(MyTest),2),testOriginal[,c(3579,3593)])\n",
            "\t\t\tSSS=(rbind(MyTrain,MyTest))\n",
            "\t\t\tordr=colnames(SSS)[order(colSds(as.matrix(SSS)),decreasing=T)]\n",
            "\t\t\tMyTrain=MyTrain[,ordr[1:450]]\t\t\n",
            "\t\t\tMyTest=MyTest[,ordr[1:450]]\t\t\t\n",
            "\t\t\tP_MLP_Preds5=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=50,Hidden1=5,Hidden2=5,IWeights=0.6)\t\t\n",
            "\t\t\tP_MLP_Preds5[,1]=exp(P_MLP_Preds5[,1])-1\n",
            "\t\t\tcat('P_MLP_Preds5:',RMSE(data.frame(tstTRG),P_MLP_Preds5),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(MyTrain,4)),trainOriginal[c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(MyTest,4)),testOriginal[c(3579:3581)])\t\t\n",
            "\t\t\tP_MLP_Preds6=GetMLPPreds(MyTrain[],MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tP_MLP_Preds6[,1]=exp(P_MLP_Preds6[,1])-1\n",
            "\t\t\tcat('P_MLP_Preds6:',RMSE(data.frame(tstTRG),P_MLP_Preds6),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(MyTrain,4)),trainOriginal[c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(MyTest,4)),testOriginal[c(3579:3581,3594)])\t\t\n",
            "\t\t\tP_MLP_Preds7=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tP_MLP_Preds7[,1]=exp(P_MLP_Preds7[,1])-1\n",
            "\t\t\tcat('P_MLP_Preds7:',RMSE(data.frame(tstTRG),P_MLP_Preds7),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=cbind(HaarTransform(MyTrain,4),trainOriginal[c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(HaarTransform((MyTest),4),testOriginal[c(3579:3581)])\t\t\n",
            "\t\t\tP_MVR_Preds1=GetMVRPreds(MyTrain,MyTest,MyTarget,Ncomp=200,Scale=True)\n",
            "\t\t\tP_MVR_Preds1[,1]=exp(P_MVR_Preds1[,1])-1\n",
            "\t\t\tcat('P_MVR_Preds1:',RMSE(data.frame(tstTRG),P_MVR_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\t\n",
            "\t\t\tThisPred=(70*P_SVM_Preds1+70*P_MVR_Preds1+70*P_MLP_Preds1+100*P_MLP_Preds3+70*P_SVM_Preds2+70*P_SVM_Preds3+50*P_MLP_Preds4+50*P_MLP_Preds5+50*P_MLP_Preds6+200*P_MLP_Preds7)/800\n",
            "\t\t\tcat('P_Ensemble:',RMSE(data.frame(tstTRG),ThisPred),'\\n   ')\t\n",
            "\t\t\t\t\n",
            "\t\t}\n",
            "\t\t\n",
            "\t\t#Training and Prediction phase for \"pH\" target\n",
            "\t\tif(TheTarget=='pH')\n",
            "\t\t{\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal[,1:3578],1),trainOriginal[c(3583,3594)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal[,1:3578],1),testOriginal[c(3583,3594)])\n",
            "\t\t\tpH_SVM_Preds1=GetSVMDepthPreds(MyTrain,MyTest,MyTarget,Cost=1000)\n",
            "\t\t\tcat('pH_SVM_Preds1:',RMSE(data.frame(tstTRG),pH_SVM_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(trainOriginal[,1:3578],trainOriginal[,3579:3594])\n",
            "\t\t\tMyTest=cbind(testOriginal[,1:3578],testOriginal[,3579:3594])\n",
            "\t\t\tpH_SVM_Preds2=GetSVMPreds(MyTrain,MyTest,MyTarget,5000)\n",
            "\t\t\tcat('pH_SVM_Preds2:',RMSE(data.frame(tstTRG),pH_SVM_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal[,1:3578],5),trainOriginal[,c(3579,3581)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal[,1:3578],5),testOriginal[,c(3579,3581)])\n",
            "\t\t\tpH_MLP_Preds1=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('pH_MLP_Preds1:',RMSE(data.frame(tstTRG),pH_MLP_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(trainOriginal,4)),trainOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(testOriginal,4)),testOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tpH_MLP_Preds2=GetMLPDepthPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\n",
            "\t\t\tcat('pH_MLP_Preds2:',RMSE(data.frame(tstTRG),pH_MLP_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal[,1:3578],4),trainOriginal[,c(3579:3582)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal[,1:3578],4),testOriginal[,c(3579:3582)])\n",
            "\t\t\tpH_MLP_Preds3=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('pH_MLP_Preds3:',RMSE(data.frame(tstTRG),pH_MLP_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(MyTrain,4)),trainOriginal[c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(MyTest,4)),testOriginal[c(3579:3581)])\t\t\n",
            "\t\t\tpH_MLP_Preds4=GetMLPPreds(MyTrain[],MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('pH_MLP_Preds4:',RMSE(data.frame(tstTRG),pH_MLP_Preds4),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(MyTrain,4)),trainOriginal[c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(MyTest,4)),testOriginal[c(3579:3581,3594)])\t\t\n",
            "\t\t\tpH_MLP_Preds5=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('pH_MLP_Preds5:',RMSE(data.frame(tstTRG),pH_MLP_Preds5),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tThisPred=(70*pH_MLP_Preds1+70*pH_MLP_Preds2+50*pH_SVM_Preds1+50*pH_MLP_Preds3+50*pH_SVM_Preds2+70*pH_MLP_Preds4+70*pH_MLP_Preds5)/430\n",
            "\t\t\tcat('pH_Ensemble:',RMSE(data.frame(tstTRG),ThisPred),'\\n   ')\t\n",
            "\t\t\t\n",
            "\t\t}\n",
            "\t\t\n",
            "\t\t#Training and Prediction phase for \"SOC\" target\n",
            "\t\tif (TheTarget=='SOC')\n",
            "\t\t{\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=cbind(MyTrain,trainOriginal[c(3581,3590,3591)])\n",
            "\t\t\tMyTest=cbind(MyTest,testOriginal[c(3581,3590,3591)])\t\t\n",
            "\t\t\tSOC_SVM_Preds1=GetSVMPreds(MyTrain,MyTest,MyTarget,10000)\n",
            "\t\t\tcat('SOC_SVM_Preds1:',RMSE(data.frame(tstTRG),SOC_SVM_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(trainOriginal[,1:3578],trainOriginal[,3579:3594])\n",
            "\t\t\tMyTest=cbind(testOriginal[,1:3578],testOriginal[,3579:3594])\n",
            "\t\t\tSOC_SVM_Preds2=GetSVMPreds(MyTrain,MyTest,MyTarget,5000)\n",
            "\t\t\tcat('SOC_SVM_Preds2:',RMSE(data.frame(tstTRG),SOC_SVM_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 3, w = 11, m = 0)\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 3, w = 11, m = 0)\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(HaarTransform(MyTrain,3),trainOriginal[c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(MyTest,3),testOriginal[c(3579:3581,3594)])\t\t\n",
            "\t\t\tSOC_MLP_Preds1=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=3,Hidden2=3,IWeights=0.5,Seed=1,N.ensemble=20)\n",
            "\t\t\tcat('SOC_MLP_Preds1:',RMSE(data.frame(tstTRG),SOC_MLP_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 3, w = 11, m = 0)\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 3, w = 11, m = 0)\n",
            "\t\t\tMyTrain=cbind(HaarTransform(MyTrain,3),trainOriginal[c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(MyTest,3),testOriginal[c(3579:3581,3594)])\t\t\n",
            "\t\t\tSOC_MLP_Preds2=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=3,Hidden2=3,IWeights=0.5,Seed=1,N.ensemble=10)\t\n",
            "\t\t\tcat('SOC_MLP_Preds2:',RMSE(data.frame(tstTRG),SOC_MLP_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console();\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 3, w = 11, m = 0)\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 3, w = 11, m = 0)\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(HaarTransform(MyTrain,4),trainOriginal[c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(MyTest,4),testOriginal[c(3579:3581)])\t\t\n",
            "\t\t\tSOC_MLP_Preds3=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=4,Hidden2=4,IWeights=0.5,Seed=1,N.ensemble=10)\n",
            "\t\t\tcat('SOC_MLP_Preds3:',RMSE(data.frame(tstTRG),SOC_MLP_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(Derivative(trainOriginal[,1:3578]),6),trainOriginal[,c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(Derivative(testOriginal[,1:3578]),6),testOriginal[,c(3579:3581)])\n",
            "\t\t\tSOC_MLP_Preds4=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=4,Hidden2=0,IWeights=0.5)\t\t\n",
            "\t\t\tcat('SOC_MLP_Preds4:',RMSE(data.frame(tstTRG),SOC_MLP_Preds4),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=HaarTransform(trainOriginal,5)\n",
            "\t\t\tMyTest=HaarTransform(testOriginal,5)\n",
            "\t\t\tSOC_MLP_Preds5=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=50,Hidden1=5,Hidden2=5,IWeights=0.6)\t\t\n",
            "\t\t\tcat('SOC_MLP_Preds5:',RMSE(data.frame(tstTRG),SOC_MLP_Preds5),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\trnk=GetRanksBySD(MyTrain,MyTest)\n",
            "\t\t\tMyTrain=MyTrain[,rnk<2500]\t\t\n",
            "\t\t\tMyTest=MyTest[,rnk<2500]\t\t\t\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(MyTrain,4)),trainOriginal[c(3579:3581)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(MyTest,4)),testOriginal[c(3579:3581)])\t\t\n",
            "\t\t\tSOC_MLP_Preds6=GetMLPPreds(MyTrain[],MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('SOC_MLP_Preds6:',RMSE(data.frame(tstTRG),SOC_MLP_Preds6),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tThisPred=(100*SOC_SVM_Preds1+50*SOC_MLP_Preds3+50*SOC_MLP_Preds2+50*SOC_MLP_Preds1+70*SOC_SVM_Preds2+100*SOC_MLP_Preds4+60*SOC_MLP_Preds5+20*SOC_MLP_Preds6)/500\n",
            "\t\t\tcat('SOC_Ensemble:',RMSE(data.frame(tstTRG),ThisPred),'\\n   ')\t\n",
            "\t\t}\n",
            "\t\t\n",
            "\t\t#Training and Prediction phase for \"Sand\" target\n",
            "\t\tif (TheTarget=='Sand')\n",
            "\t\t{\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 3, w = 11, m = 0)\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 3, w = 11, m = 0)\n",
            "\t\t\tMyTrain=cbind(MyTrain,trainOriginal[c(3581,3583,3585,3586,3588,3590,3591:3592,3594)])\n",
            "\t\t\tMyTest=cbind(MyTest,testOriginal[c(3581,3583,3585,3586,3588,3590,3591:3592,3594)])\t\t\n",
            "\t\t\tSand_SVM_Preds1=GetSVMPreds(MyTrain,MyTest,MyTarget,5000)\n",
            "\t\t\tcat('Sand_SVM_Preds1:',RMSE(data.frame(tstTRG),Sand_SVM_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tSand_SVM_Preds2=GetSVMPreds(trainOriginal,testOriginal,MyTarget,Cost=10000)#OK\n",
            "\t\t\tcat('Sand_SVM_Preds2:',RMSE(data.frame(tstTRG),Sand_SVM_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal\n",
            "\t\t\tMyTest=testOriginal\n",
            "\t\t\tSSS=(rbind(MyTrain,MyTest))\n",
            "\t\t\tMyTrain=SSS[(1:nrow(trainOriginal)),]\n",
            "\t\t\tMyTest=SSS[-(1:nrow(trainOriginal)),]\n",
            "\t\t\tordr=colnames(SSS)[order(colSds(as.matrix(SSS)),decreasing=T)]\n",
            "\t\t\tMyTrain=MyTrain[,ordr[1:2000]]\t\t\n",
            "\t\t\tMyTest=MyTest[,ordr[1:2000]]\t\t\n",
            "\t\t\tMyTrain=HaarTransform(Derivative(MyTrain),3)\n",
            "\t\t\tMyTest=HaarTransform(Derivative(MyTest),3)\n",
            "\t\t\tSand_SVM_Preds3=GetSVMPreds(MyTrain,MyTest,MyTarget,10000)\n",
            "\t\t\tcat('Sand_SVM_Preds3:',RMSE(data.frame(tstTRG),Sand_SVM_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tSSS=(rbind(MyTrain,MyTest))\n",
            "\t\t\tMyTrain=SSS[(1:nrow(trainOriginal)),]\n",
            "\t\t\tMyTest=SSS[-(1:nrow(trainOriginal)),]\n",
            "\t\t\tordr=colnames(SSS)[order(colSds(as.matrix(SSS)),decreasing=T)]\n",
            "\t\t\tMyTrain=MyTrain[,ordr[1:1500]]\t\t\n",
            "\t\t\tMyTest=MyTest[,ordr[1:1500]]\t\t\n",
            "\t\t\tMyTrain=HaarTransform(Derivative(MyTrain),3)\n",
            "\t\t\tMyTest=HaarTransform(Derivative(MyTest),3)\n",
            "\t\t\tSand_SVM_Preds4=GetSVMPreds(MyTrain,MyTest,MyTarget,10000)\n",
            "\t\t\tcat('Sand_SVM_Preds4:',RMSE(data.frame(tstTRG),Sand_SVM_Preds4),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=HaarTransform(trainOriginal[,1:3578],4)\n",
            "\t\t\tMyTest=HaarTransform(testOriginal[,1:3578],4)\n",
            "\t\t\tMyTrain=savitzkyGolay(MyTrain, p = 2, w = 3, m = 1)\n",
            "\t\t\tMyTest=savitzkyGolay(MyTest, p = 2, w = 3, m = 1)\n",
            "\t\t\tMyTrain=cbind(MyTrain,trainOriginal[c(3579,3593)])\n",
            "\t\t\tMyTest=cbind(MyTest,testOriginal[c(3579,3593)])\t\t\n",
            "\t\t\tSand_MLP_Preds1=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=4,Hidden2=4,IWeights=0.6,Seed=1,N.ensemble=10)\n",
            "\t\t\tcat('Sand_MLP_Preds1:',RMSE(data.frame(tstTRG),Sand_MLP_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=HaarTransform(MyTrain,4)\n",
            "\t\t\tMyTest=HaarTransform(MyTest,4)\n",
            "\t\t\tMTT=rbind(MyTrain,MyTest)\n",
            "\t\t\tMTT=WekPCA(MTT,0.9995)\n",
            "\t\t\tMyTrain=MTT[1:nrow(MyTrain),]\n",
            "\t\t\tMyTest=MTT[-(1:nrow(MyTrain)),]\n",
            "\t\t\tMyTrain=cbind(MyTrain,trainOriginal[c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(MyTest,testOriginal[c(3579:3581,3594)])\t\n",
            "\t\t\tSand_MLP_Preds2=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=200,Hidden1=5,Hidden2=5,IWeights=0.5,Seed=1,N.ensemble=30)\n",
            "\t\t\tcat('Sand_MLP_Preds2:',RMSE(data.frame(tstTRG),Sand_MLP_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=HaarTransform(trainOriginal,5)\n",
            "\t\t\tMyTest=HaarTransform(testOriginal,5)\n",
            "\t\t\tSand_MLP_Preds3=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=50,Hidden1=4,Hidden2=0,IWeights=0.5)\t\t\n",
            "\t\t\tcat('Sand_MLP_Preds3:',RMSE(data.frame(tstTRG),Sand_MLP_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=HaarTransform(trainOriginal,5)\n",
            "\t\t\tMyTest=HaarTransform(testOriginal,5)\n",
            "\t\t\tSand_MLP_Preds4=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=50,Hidden1=5,Hidden2=5,IWeights=0.6)\t\t\n",
            "\t\t\tcat('Sand_MLP_Preds4:',RMSE(data.frame(tstTRG),Sand_MLP_Preds4),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal[,1:3578]\n",
            "\t\t\tMyTest=testOriginal[,1:3578]\n",
            "\t\t\tMyTrain=cbind(HaarTransform(Derivative(MyTrain),2),trainOriginal[,c(3579,3593)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(Derivative(MyTest),2),testOriginal[,c(3579,3593)])\n",
            "\t\t\tSSS=(rbind(MyTrain,MyTest))\n",
            "\t\t\tMyTrain=SSS[(1:nrow(trainOriginal)),]\n",
            "\t\t\tMyTest=SSS[-(1:nrow(trainOriginal)),]\n",
            "\t\t\tordr=colnames(SSS)[order(colSds(as.matrix(SSS)),decreasing=T)]\n",
            "\t\t\tMyTrain=MyTrain[,ordr[1:450]]\t\t\n",
            "\t\t\tMyTest=MyTest[,ordr[1:450]]\t\t\n",
            "\t\t\tSand_MLP_Preds5=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=50,Hidden1=5,Hidden2=5,IWeights=0.6)\t\t\n",
            "\t\t\tcat('Sand_MLP_Preds5:',RMSE(data.frame(tstTRG),Sand_MLP_Preds5),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(Derivative(HaarTransform(trainOriginal,4)),trainOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tMyTest=cbind(Derivative(HaarTransform(testOriginal,4)),testOriginal[,c(3579:3581,3594)])\n",
            "\t\t\tSand_MLP_Preds6=GetMLPDepthPreds(MyTrain,MyTest,MyTarget,Iters=100,Hidden1=5,Hidden2=5,IWeights=0.5)\n",
            "\t\t\tcat('Sand_MLP_Preds6:',RMSE(data.frame(tstTRG),Sand_MLP_Preds6),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=cbind(HaarTransform(trainOriginal[,1:3578],4),trainOriginal[,c(3579:3582)])\n",
            "\t\t\tMyTest=cbind(HaarTransform(testOriginal[,1:3578],4),testOriginal[,c(3579:3582)])\n",
            "\t\t\tSand_MLP_Preds7=GetMLPPreds(MyTrain,MyTest,MyTarget,Iters=150,Hidden1=5,Hidden2=5,IWeights=0.5)\t\t\n",
            "\t\t\tcat('Sand_MLP_Preds7:',RMSE(data.frame(tstTRG),Sand_MLP_Preds7),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tSand_Gauss_Preds1=GetGaussPreds(trainOriginal,testOriginal,MyTarget,Kernel='rbfdot',Tol=0.05,Var=0.01)\n",
            "\t\t\tcat('Sand_Gauss_Preds1:',RMSE(data.frame(tstTRG),Sand_Gauss_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\n",
            "\t\t\tflush.console()\n",
            "\t\t\tSand_Gauss_Preds2=GetGaussPreds(trainReduced,testReduced,MyTarget,Kernel='rbfdot',Tol=0.05,Var=0.01)\n",
            "\t\t\tcat('Sand_Gauss_Preds2:',RMSE(data.frame(tstTRG),Sand_Gauss_Preds2),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tSand_Gauss_Preds3=GetGaussPreds(trainOriginal,testOriginal,MyTarget,Kernel='polydot',Tol=0.001,Var=0.1)\n",
            "\t\t\tcat('Sand_Gauss_Preds3:',RMSE(data.frame(tstTRG),Sand_Gauss_Preds3),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=trainOriginal\n",
            "\t\t\tMyTest=testOriginal\n",
            "\t\t\tSSS=(rbind(MyTrain,MyTest))\n",
            "\t\t\tordr=colnames(SSS)[order(colSds(as.matrix(SSS)),decreasing=T)]\n",
            "\t\t\tMyTrain=MyTrain[,ordr[1:2000]]\t\t\n",
            "\t\t\tMyTest=MyTest[,ordr[1:2000]]\t\t\t\n",
            "\t\t\tSand_MVR_Preds1=GetMVRPreds(MyTrain,MyTest,MyTarget,120,True)\n",
            "\t\t\tcat('Sand_MVR_Preds1:',RMSE(data.frame(tstTRG),Sand_MVR_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tflush.console()\n",
            "\t\t\tMyTrain=HaarTransform(trainOriginal,5)\n",
            "\t\t\tMyTest=HaarTransform(testOriginal,5)\n",
            "\t\t\tSand_NNET_Preds1=GetNNETPreds(MyTrain,MyTest,MyTarget,Size=10,Rang=0.5,Decay=0.1,Iters=100)\t\t\n",
            "\t\t\tcat('Sand_NNET_Preds1:',RMSE(data.frame(tstTRG),Sand_NNET_Preds1),'   ')\t\n",
            "\t\t\tflush.console();gc();cat('\\n');\n",
            "\t\t\t\n",
            "\t\t\tThisPred=(15*Sand_Gauss_Preds1+30*Sand_SVM_Preds2+10*Sand_Gauss_Preds2+20*Sand_Gauss_Preds3+15*Sand_MVR_Preds1+50*Sand_SVM_Preds3+50*Sand_SVM_Preds4+10*Sand_MLP_Preds3+10*Sand_NNET_Preds1+70*Sand_MLP_Preds4+120*Sand_MLP_Preds5+30*Sand_MLP_Preds6+60*Sand_MLP_Preds7+100*Sand_SVM_Preds1+100*Sand_MLP_Preds2+100*Sand_MLP_Preds1)/790\n",
            "\t\t\tcat('Sand_Ensemble:',RMSE(data.frame(tstTRG),ThisPred),'   ')\t\n",
            "\t\t}\n",
            "\n",
            "\t\tThisPred[,1]=ifelse(ThisPred[,1]<min(ThisTarget),min(ThisTarget),ThisPred[,1])\n",
            "\t\tThisPred[,1]=ifelse(ThisPred[,1]>max(ThisTarget),max(ThisTarget),ThisPred[,1])\n",
            "\t\tflush.console()\n",
            "\t\tcvsm=cvsm+RMSE(data.frame(tstTRG),ThisPred)\n",
            "\t\tcat('\\n')\n",
            "\t}\n",
            "\tcat('  CV:',cvsm/nf,'\\n')\n",
            "\tmsm=msm+cvsm/nf\n",
            "\tflush.console();gc();\n",
            "}\n",
            "\n",
            "cat('OverallCV:',msm/5)\n",
            "\n",
            "****************************************************************************************************\n",
            "args <- commandArgs(trailingOnly = TRUE)\n",
            "xyz <- read.csv(file=args[1])\n",
            "pdf(args[2])\n",
            "scatterplot3d::scatterplot3d(xyz, color=\"blue\", pch=19, xlab=\"Statistical Distance\", ylab=\"Length of Simulation [s]\", zlab=\"Match Percentage [%]\", type=\"h\")\n",
            "\n",
            "****************************************************************************************************\n",
            "library(httr)\n",
            "\n",
            "# 1. Find OAuth settings for vimeo:\n",
            "#    http://vimeo.com/api/docs/authentication\n",
            "oauth_endpoints(\"vimeo\")\n",
            "\n",
            "# 2. Register an application at https://developer.vimeo.com/apps\n",
            "#    Replace key and secret below.\n",
            "myapp <- oauth_app(\"vimeo\",\n",
            "  key = \"bd535bc38ed5caccd79330ff33075eb9\",\n",
            "  secret = \"51ab8cb2cbb8b7eb\"\n",
            ")\n",
            "\n",
            "# 3. Get OAuth credentials\n",
            "vimeo_token <- oauth2.0_token(\n",
            "  oauth_endpoints(\"vimeo\"), myapp,\n",
            "  as_header = TRUE,\n",
            "  use_basic_auth = TRUE\n",
            ")\n",
            "\n",
            "# 4. Use API\n",
            "req <- GET(\n",
            "  \"https://api.vimeo.com/me/videos\",\n",
            "  config(token = vimeo_token)\n",
            ")\n",
            "stop_for_status(req)\n",
            "str(jsonlite::fromJSON(content(req, \"text\")))\n",
            "\n",
            "****************************************************************************************************\n",
            "#' This collection of functions is used for the US National\n",
            "#' Highway Traffic Safety Administration's Fatality Analysis Reporting System,\n",
            "#' which is a nationwide census providing the American public yearly data\n",
            "#' regarding fatal injuries suffered in motor vehicle traffic crashes.\n",
            "#' @importFrom tidyr spread\n",
            "#' @importFrom maps map\n",
            "#' @importFrom magrittr %>%\n",
            "#' @importFrom dplyr tbl_df\n",
            "#' @importFrom dplyr mutate\n",
            "#' @importFrom dplyr select\n",
            "#' @importFrom dplyr filter\n",
            "#' @importFrom dplyr summarize\n",
            "#' @importFrom dplyr group_by\n",
            "#' @importFrom dplyr bind_rows\n",
            "#' @importFrom readr read_csv\n",
            "#'\n",
            "#'\n",
            "#'\n",
            "#' @title fars_read\n",
            "#'\n",
            "#' @description This function checks for the existence of the file in folder, and if the file\n",
            "#' does not exist, stops to let the user know that file does not exist. Otherwise,\n",
            "#' the file is read in and converted to a data table.\n",
            "#'\n",
            "#' @param filename The name of the file to read into R.\n",
            "#' @return fars_read returns a tibble or lets user know if file doesn't exist.\n",
            "#'\n",
            "#' @export\n",
            "\n",
            "fars_read <- function(filename) {\n",
            "        if(!file.exists(filename))\n",
            "                stop(\"file '\", filename, \"' does not exist\")\n",
            "        data <- suppressMessages({\n",
            "                readr::read_csv(filename, progress = FALSE)\n",
            "        })\n",
            "        dplyr::tbl_df(data)\n",
            "}\n",
            "#'\n",
            "#' @title make_filename\n",
            "#' @description This function takes year as an argument, converts to integer, and returns a filename\n",
            "#' with that can be read as \"accident_\",year,\".csv.bz2\")\n",
            "#'\n",
            "#' @param year Year of data to be read.\n",
            "#' @return make_filename returns string filename of data set to import.\n",
            "\n",
            "#' @export\n",
            "\n",
            "make_filename <- function(year) {\n",
            "        year <- as.integer(year)\n",
            "        sprintf(\"accident_%d.csv.bz2\", year)\n",
            "}\n",
            "#'\n",
            "#' @title fars_read_years\n",
            "#' @description This function iterates over a list of years provided by user, first making a filename to\n",
            "#' read from the folder, trying to read the file and if successful, creating a year variable\n",
            "#' equal to the element, and finishing by selecting the month and year. If unable to read\n",
            "#' file, throws back an error.\n",
            "\n",
            "#' @note Error is returned if file is not valid name, which is due to invalid year.\n",
            "#'\n",
            "#' @param years A list of years for filenames to be read into R.\n",
            "#' @return fars_read_years returns a list of tibbles with year and month as columns\n",
            "\n",
            "#' @export\n",
            "\n",
            "fars_read_years <- function(years) {\n",
            "        lapply(years, function(year) {\n",
            "                file <- make_filename(year)\n",
            "                tryCatch({\n",
            "                        dat <- fars_read(file)\n",
            "                        dplyr::mutate(dat, year = year) %>%\n",
            "                                dplyr::select(MONTH, year)\n",
            "                }, error = function(e) {\n",
            "                        warning(\"invalid year: \", year)\n",
            "                        return(NULL)\n",
            "                })\n",
            "        })\n",
            "}\n",
            "#'\n",
            "#'\n",
            "#' @title fars_summarize_years\n",
            "#' @description This function takes an argument that is a year, reads the data in if it exists,\n",
            "#' keeping month and year, and giving the number of observations grouped by month and year.\n",
            "#'\n",
            "#' @param years A list of years that were read into R for summarization.\n",
            "#' @return fars_summarize_years returns a tibble of number of accidents for each year with month as column\n",
            "\n",
            "#' @export\n",
            "\n",
            "fars_summarize_years <- function(years) {\n",
            "        dat_list <- fars_read_years(years)\n",
            "        dplyr::bind_rows(dat_list) %>%\n",
            "                dplyr::group_by(year, MONTH) %>%\n",
            "                dplyr::summarize(n = n()) %>%\n",
            "                tidyr::spread(year, n)\n",
            "}\n",
            "#'\n",
            "#' @title fars_map_state\n",
            "#' @description This function expands on the previous functions by now including a state.num argument. The\n",
            "#' Here, the data are read in, and then checked for the presence of the state, given by state.num.\n",
            "#' If the state is not in the data, the function stops. If state is present, data are filtered to\n",
            "#' this state only and checked for number of accidents that occurred. If none, message is printed,\n",
            "#' but if there is data, then the locations by latitude and longitude are plotted.\n",
            "#'\n",
            "#' @param state.num A number identifier for state of interest\n",
            "#' @param year A year of data to graph locations of accidents.\n",
            "#' @return fars_map_state returns a plot object.\n",
            "#' @note returns an error if state number is invalid.\n",
            "#' @export\n",
            "\n",
            "fars_map_state <- function(state.num, year) {\n",
            "        filename <- make_filename(year)\n",
            "        data <- fars_read(filename)\n",
            "        state.num <- as.integer(state.num)\n",
            "\n",
            "        if(!(state.num %in% unique(data$STATE)))\n",
            "                stop(\"invalid STATE number: \", state.num)\n",
            "        data.sub <- dplyr::filter(data, STATE == state.num)\n",
            "        if(nrow(data.sub) == 0L) {\n",
            "                message(\"no accidents to plot\")\n",
            "                return(invisible(NULL))\n",
            "        }\n",
            "        is.na(data.sub$LONGITUD) <- data.sub$LONGITUD > 900\n",
            "        is.na(data.sub$LATITUDE) <- data.sub$LATITUDE > 90\n",
            "        with(data.sub, {\n",
            "                maps::map(\"state\", ylim = range(LATITUDE, na.rm = TRUE),\n",
            "                          xlim = range(LONGITUD, na.rm = TRUE))\n",
            "                graphics::points(LONGITUD, LATITUDE, pch = 46)\n",
            "        })\n",
            "}\n",
            "#'\n",
            "#' @examples\n",
            "#' \\dontrun{fars_read(filename = \"accident_2018.csv.bz2\")}\n",
            "#' \\dontrun{make_filename(year = \"1987\")}\n",
            "#' \\dontrun{fars_read_years(years = c(1987,1988,1989))}\n",
            "#' \\dontrun{fars_summarize_years(years = c(1987,1988,1989))}\n",
            "#' \\dontrun{fars_map_state(state.num = 1,year = 1987)}\n",
            "\n",
            "****************************************************************************************************\n",
            "library(\"RWeka\")\n",
            "library(\"tm\")\n",
            "library(\"SnowballC\")\n",
            "\n",
            "conn <- file(\"./job/data.frame/27jobs.txt\", open=\"r\")\n",
            "jobsData <- readLines(conn)\n",
            "close(conn)\n",
            "\n",
            "jobs <- VCorpus(VectorSource(jobsData))\n",
            "jobs <- tm_map(jobs, content_transformer(gsub), pattern = \"[[:punct:]]\", conn <- file(\"./job/data.frame/27jobs.txt\", open=\"r\")\n",
            "               jobsData <- readLines(conn)\n",
            "               close(conn)\n",
            "               \n",
            "               jobs <- VCorpus(VectorSource(jobsData))\n",
            "               jobs <- tm_map(jobs, content_transformer(gsub), pattern = \"[[:punct:]]\", \n",
            "                              replacement = \" \")\n",
            "               jobs <- tm_map(jobs, stripWhitespace)\n",
            "               #jobs <- tm_map(jobs, removePunctuation) - is done above\n",
            "               #jobs <- tm_map(jobs, removeNumbers)\n",
            "               jobs <- tm_map(jobs, content_transformer(tolower))\n",
            "               jobs <- tm_map(jobs, stemDocument)\n",
            "               customStopWords <- c(\"and\", \"veri\", \"for\")\n",
            "               jobs <- tm_map(jobs, removeWords, customStopWords)\n",
            "               replacement = \" \")\n",
            "jobs <- tm_map(jobs, stripWhitespace)\n",
            "#jobs <- tm_map(jobs, removePunctuation) - is done above\n",
            "#jobs <- tm_map(jobs, removeNumbers)\n",
            "jobs <- tm_map(jobs, content_transformer(tolower))\n",
            "jobs <- tm_map(jobs, stemDocument)\n",
            "customStopWords <- c(\"and\", \"veri\", \"for\")\n",
            "jobs <- tm_map(jobs, removeWords, customStopWords)\n",
            "\n",
            "\n",
            "nGramTok <- function(x) NGramTokenizer(x, Weka_control(min = 1, max = 1))\n",
            "tdm <- \n",
            "  TermDocumentMatrix(jobs, list(tokenize = nGramTok, stopwords = TRUE))\n",
            "\n",
            "\n",
            "findFreqTerms(tdm, 4)\n",
            "\n",
            "#findMostFreqTerms(tdm)\n",
            "\n",
            "inspect(tdm)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "egTz10zKWzfk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}